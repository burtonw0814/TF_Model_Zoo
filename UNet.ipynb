{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. ...\n",
    "# InInternational Conference on Medical image computing and computer-assisted intervention 2015 Oct 5 (pp. 234-241). Springer, Cham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of .png files in path\n",
    "def get_num_files(path_ground):\n",
    "\n",
    "    ground_files=glob.glob(path_ground + \"*.png\")\n",
    "    num_files=int(len(glob.glob(path_ground + \"*.png\")))\n",
    "    \n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dims(image):\n",
    "    image=np.array(image)\n",
    "    depth=4\n",
    "    #Start with dim 1\n",
    "    if image.shape[0]%(2**depth)!=0:\n",
    "        lb=int(image.shape[0]/(2**depth))\n",
    "        while image.shape[0]<((2**depth)*(lb+1)):\n",
    "            image=np.concatenate((image,np.zeros((1,image.shape[1]))),axis=0)\n",
    "\n",
    "    if image.shape[1]%(2**depth)!=0:\n",
    "        lb=int(image.shape[1]/(2**depth))\n",
    "        while image.shape[1]<((2**depth)*(lb+1)):\n",
    "            image=np.concatenate((image,np.zeros((image.shape[0],1))),axis=1)\n",
    "                    \n",
    "    return image\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_translate_seg_version(input_block,ground_truth_block,y_dir,x_dir,reflect_flag):\n",
    "    # Input_block is [height, width, depth=1]\n",
    "    # Ground_truth_block is [height, width, depth=1]\n",
    "    \n",
    "    imsize=input_block.shape\n",
    "    temp=np.empty((imsize[0],imsize[1],imsize[2]))\n",
    "    temp_ground=np.empty((imsize[0],imsize[1],imsize[2]))\n",
    "    y_abs=np.absolute(y_dir)\n",
    "    x_abs=np.absolute(x_dir)\n",
    "    \n",
    "    # Reflection about y-axis (width)\n",
    "    if reflect_flag==1:\n",
    "        input_block=np.flip(input_block,1)\n",
    "        ground_truth_block=np.flip(ground_truth_block,1)        \n",
    "    \n",
    "    # Vertical translation\n",
    "    if y_dir != 0: \n",
    "        height_pad=np.zeros((y_abs,imsize[1],imsize[2]))\n",
    "        if y_dir>0: # Shift up --> attach zeros to bottom\n",
    "            temp=np.concatenate((input_block[y_abs:,:,:],height_pad),axis=0)\n",
    "            temp_ground=np.concatenate((ground_truth_block[y_abs:,:,:],height_pad),axis=0)\n",
    "        else: # Shift down --> attach zeros to top\n",
    "            temp=np.concatenate((height_pad,input_block[:(-1*y_abs),:,:]),axis=0)\n",
    "            temp_ground=np.concatenate((height_pad,ground_truth_block[:(-1*y_abs),:,:]),axis=0)\n",
    "    else: \n",
    "        temp=input_block\n",
    "        temp_ground=ground_truth_block\n",
    "        \n",
    "    # Horizontal translation\n",
    "    if x_dir!=0:\n",
    "        width_pad=np.zeros((imsize[0],x_abs,imsize[2]))\n",
    "        if x_dir>0:\n",
    "            temp2=np.concatenate((width_pad,temp[:,:(-1*x_abs),:]),axis=1)\n",
    "            temp2_ground=np.concatenate((width_pad,temp_ground[:,:(-1*x_abs),:]),axis=1)\n",
    "        else: \n",
    "            temp2=np.concatenate((temp[:,x_abs:,:],width_pad),axis=1)\n",
    "            temp2_ground=np.concatenate((temp_ground[:,x_abs:,:],width_pad),axis=1)\n",
    "    else:\n",
    "        temp2=temp\n",
    "        temp2_ground=temp_ground\n",
    "        \n",
    "    # Returns tensors with same dimensions as the inputs\n",
    "    return temp2, temp2_ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_files(num_files):\n",
    "    x = ([[i] for i in range(num_files)])\n",
    "    shuflist=random.sample(x,len(x))\n",
    "    list_files=[]\n",
    "\n",
    "    s=''\n",
    "    for i in range(num_files):\n",
    "        ID=str(shuflist[i][0])\n",
    "        while len(ID)<6:\n",
    "            ID='0'+ID\n",
    "        list_files.append(ID)\n",
    "            \n",
    "    return list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer wrappers\n",
    "def conv_layer(inputs, channels_in, channels_out, stvs, strides=1, scopename=\"Conv\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        s=''\n",
    "        weightname=(scopename,'_weights')\n",
    "        biasname=(scopename,'_bias')\n",
    "        \n",
    "        w=tf.Variable(tf.random_normal([3, 3, channels_in, channels_out],stddev=stvs),name=s.join(weightname))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        \n",
    "        b=tf.Variable(tf.random_normal([channels_out],stddev=stvs),name=s.join(biasname))\n",
    "        tf.summary.histogram((\"Weight\" + scopename),w)\n",
    "        tf.summary.histogram((\"Bias\" + scopename),b)\n",
    "        \n",
    "        x = tf.nn.conv2d(inputs, w, strides=[1, strides, strides, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        #x=tf.contrib.layers.layer_norm(x)\n",
    "        epsilon = 1e-3\n",
    "        scale = tf.Variable(tf.ones([x.get_shape()[-1]]))\n",
    "        beta = tf.Variable(tf.zeros([x.get_shape()[-1]]))\n",
    "        batch_mean, batch_var = tf.nn.moments(x,[0,1,2])\n",
    "        x=tf.nn.batch_normalization(x, batch_mean, batch_var, beta, scale, epsilon)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2, scopename=\"Pool\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "\n",
    "def upconv2d(x, channels_in, channels_out, stvs, stride=2, scopename=\"Upconv\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        w=tf.Variable(tf.random_normal([2, 2, channels_out, channels_in],stddev=stvs))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        \n",
    "        x_shape = tf.shape(x)\n",
    "        output_shape = tf.stack([x_shape[0], x_shape[1]*2, x_shape[2]*2, x_shape[3]//2]) # [BS doubleheight doubl width  halvedepth]\n",
    "        return tf.nn.conv2d_transpose(x, w, output_shape, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def concatenate(in1, in2, scopename=\"Concat\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        return tf.concat([in1, in2], 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of network\n",
    "def conv_net(x, inputdepth):\n",
    "    stvs=0.01\n",
    "    depthstart=64\n",
    "    num_classes=2\n",
    "\n",
    "    conv1a = conv_layer(x, inputdepth, depthstart, stvs,scopename=\"conv1a\") \n",
    "    conv1b = conv_layer(conv1a, depthstart, depthstart, stvs, scopename=\"conv1b\")\n",
    "    pooled1 = maxpool2d(conv1b,scopename=\"pooled1\")\n",
    "        \n",
    "    conv2a = conv_layer(pooled1, depthstart, depthstart*2, stvs,scopename=\"conv2a\") \n",
    "    conv2b = conv_layer(conv2a, depthstart*2, depthstart*2, stvs, scopename=\"conv2b\")\n",
    "    pooled2 = maxpool2d(conv2b,scopename=\"pooled2\")\n",
    "    \n",
    "    conv3a = conv_layer(pooled2, depthstart*2, depthstart*4, stvs,scopename=\"conv3a\") \n",
    "    conv3b = conv_layer(conv3a, depthstart*4, depthstart*4, stvs, scopename=\"conv3b\")\n",
    "    pooled3 = maxpool2d(conv3b,scopename=\"pooled3\")\n",
    "    \n",
    "    conv4a = conv_layer(pooled3, depthstart*4, depthstart*8, stvs,scopename=\"conv4a\") \n",
    "    conv4b = conv_layer(conv4a, depthstart*8, depthstart*8, stvs, scopename=\"conv4b\")\n",
    "    pooled4 = maxpool2d(conv4b,scopename=\"pooled4\")\n",
    "    \n",
    "    conv5a = conv_layer(pooled4, depthstart*8, depthstart*16, stvs,scopename=\"conv5a\") \n",
    "    conv5b = conv_layer(conv5a, depthstart*16, depthstart*16, stvs, scopename=\"conv5b\")\n",
    "    conv5c = conv_layer(conv5b, depthstart*16, depthstart*16, stvs, scopename=\"conv5c\")\n",
    "    \n",
    "    # Begin upsampling\n",
    "    upconv1=upconv2d(conv5c, depthstart*16, depthstart*8, stvs, scopename=\"upconv1\")\n",
    "    conc1=concatenate(conv4b,upconv1,scopename=\"concat1\")\n",
    "    conv6a = conv_layer(conc1, depthstart*16, depthstart*8, stvs,scopename=\"conv6a\")\n",
    "    conv6b = conv_layer(conv6a, depthstart*8, depthstart*8, stvs, scopename=\"conv6b\")\n",
    "    \n",
    "    upconv2=upconv2d(conv6b, depthstart*8, depthstart*4, stvs, scopename=\"upconv2\")\n",
    "    conc2=concatenate(conv3b,upconv2,scopename=\"concat2\")\n",
    "    conv7a = conv_layer(conc2, depthstart*8, depthstart*4, stvs,scopename=\"conv7a\")\n",
    "    conv7b = conv_layer(conv7a, depthstart*4, depthstart*4, stvs, scopename=\"conv7b\")\n",
    "    \n",
    "    upconv3=upconv2d(conv7b, depthstart*4, depthstart*2, stvs, scopename=\"upconv3\")\n",
    "    conc3=concatenate(conv2b,upconv3,scopename=\"concat3\")\n",
    "    conv8a = conv_layer(conc3, depthstart*4, depthstart*2, stvs,scopename=\"conv8a\")\n",
    "    conv8b = conv_layer(conv8a, depthstart*2, depthstart*2, stvs, scopename=\"conv8b\")\n",
    "    \n",
    "    upconv4=upconv2d(conv8b, depthstart*2, depthstart, stvs, scopename=\"upconv4\")\n",
    "    conc4=concatenate(conv1b,upconv4,scopename=\"concat4\")\n",
    "    conv9a = conv_layer(conc4, depthstart*2, depthstart, stvs,scopename=\"conv9a\")\n",
    "    conv9b = conv_layer(conv9a, depthstart, depthstart, stvs, scopename=\"conv9b\")\n",
    "        \n",
    "    # Reduce depth to num_classes\n",
    "    with tf.name_scope(\"Logs\"):\n",
    "        w=tf.Variable(tf.random_normal([1, 1, depthstart, num_classes],stddev=stvs))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        \n",
    "        b=tf.Variable(tf.random_normal([num_classes],stddev=stvs))\n",
    "\n",
    "        loglayer = tf.nn.conv2d(conv9b, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        loglayer = tf.nn.bias_add(loglayer,b)\n",
    "        \n",
    "    return loglayer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice loss function -- Defined according to the V-net paper by Milletari et al\n",
    "# Milletari F, Navab N, Ahmadi SA. V-net: Fully convolutional neural networks for volumetric medical image segmentation. ...\n",
    "# In3D Vision (3DV), 2016 Fourth International Conference on 2016 Oct 25 (pp. 565-571). IEEE.\n",
    "def dice_loss(logits, onehot_labels):\n",
    "    with tf.name_scope(\"Dice_Loss\"):\n",
    "\n",
    "        eps = 1e-5\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "        intersection = tf.reduce_sum(prediction * onehot_labels)\n",
    "        union =  eps + tf.reduce_sum(prediction) + tf.reduce_sum(onehot_labels)\n",
    "        dice_loss = -(2 * intersection/ (union))\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(image, num_classes): # Image is an [m  n] atrix\n",
    "    \n",
    "    # Make sure ground truth image is either 0 or 1, not 0 or 255\n",
    "    if np.amax(image>0):\n",
    "        image=np.divide(image,np.amax(image))\n",
    "    image=image.astype(int)\n",
    "    \n",
    "    b=np.zeros((image.shape[0],image.shape[1],num_classes))\n",
    "    for kk in range(image.shape[0]):\n",
    "        for jj in range(image.shape[1]):\n",
    "            #b[kk, range(image.shape[1]), image[kk,:]]=1\n",
    "            b[kk, jj, image[kk,jj]]=1\n",
    "    \n",
    "    # b is the one-hot version of image with dimensions [m n num_classes]\n",
    "    return b \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(input_depth, num_classes):\n",
    "    \n",
    "    # Define placeholders\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        X = tf.placeholder(tf.float32, [None, None, None, input_depth])\n",
    "    with tf.name_scope(\"Ground_Truth\"):\n",
    "        Y = tf.placeholder(tf.float32, [None, None, None, num_classes])\n",
    "    \n",
    "    # Define flow graph\n",
    "    logits = conv_net(X, input_depth)\n",
    "\n",
    "    # Prediction function for evaluating accuracy\n",
    "    with tf.name_scope(\"Softmax\"):\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Define Loss\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        loss_op=dice_loss(logits,Y)\n",
    "        #regularizer = tf.contrib.layers.l2_regularizer(scale=0.0001)\n",
    "        #reg_variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        #reg_term = tf.contrib.layers.apply_regularization(regularizer, reg_variables)\n",
    "        #loss_op += reg_term\n",
    "        tf.summary.scalar(\"Loss\",loss_op)\n",
    "\n",
    "    # Define optimizer\n",
    "    with tf.name_scope(\"Optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)    \n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "        \n",
    "    # Evaluate model\n",
    "    with tf.name_scope(\"Accuracy\"):\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, axis=3), tf.argmax(Y, axis=3))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\",accuracy)\n",
    "        \n",
    "    with tf.name_scope(\"Metrics\"):\n",
    "        # Dice similarity coefficient\n",
    "        eps = 1e-5\n",
    "        intersection = tf.reduce_sum(prediction * Y)\n",
    "        union =  eps + tf.reduce_sum(prediction) + tf.reduce_sum(Y)\n",
    "        dice = (2 * intersection/ (union))\n",
    "        tf.summary.scalar(\"Dice_Similarity_Coefficient\",dice)\n",
    "\n",
    "        # IoU\n",
    "        #iou=tf.metrics.mean_iou(Y,prediction,num_classes)\n",
    "        #tf.summary.scalar(\"IoU\",iou)\n",
    "        \n",
    "        # Images for TensorBoard\n",
    "        tf.summary.image('Predict', tf.cast(tf.expand_dims(tf.argmax(logits ,axis=3), 3),tf.float32), input_depth)\n",
    "        tf.summary.image('Ground', tf.cast(tf.expand_dims(tf.argmax(Y ,axis=3), 3),tf.float32), input_depth)  \n",
    "    \n",
    "        # Confusion Matrix\n",
    "        batch_confusion = tf.confusion_matrix(tf.reshape(tf.argmax(Y,axis=3),[-1]),tf.reshape(tf.argmax(prediction,axis=3),[-1]),num_classes=num_classes,name='Batch_confusion')\n",
    "\n",
    "    #Define writer for Tensorboard\n",
    "    writer=tf.summary.FileWriter(\"/output/1\")\n",
    "    summ=tf.summary.merge_all()\n",
    "\n",
    "    # Initialize the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    #Define saver for model saver\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    return X, Y, logits, prediction, loss_op, train_op, accuracy, batch_confusion, dice, writer, summ, init, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set hyperparameters, etc.\n",
    "learning_rate = 0.00001\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 1\n",
    "input_depth = 1\n",
    "num_classes = 2 \n",
    "\n",
    "display_step = 480\n",
    "validation_step = 480\n",
    "save_step = 960\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode=True\n",
    "tf.reset_default_graph()\n",
    "X, Y, logits, prediction, loss_op, train_op, accuracy, batch_confusion, dice, writer, summ, init, saver = build_graph(input_depth, num_classes)\n",
    "\n",
    "# Some flags\n",
    "mode='j'\n",
    "plane_view='Sagittal';\n",
    "#plane_view='Coronal';\n",
    "#plane_view='Transverse';\n",
    "\n",
    "# Distinguish paths between running on local notebook vs. running in the cloud\n",
    "if mode=='j':    \n",
    "    imdpath=\"/path/to/dir/Knee_MRI3/Femur/Train/\" + plane_view + \"/Imd/\"\n",
    "    pxdpath=\"/path/to/dir/Knee_MRI3/Femur/Train/\" + plane_view + \"/Pxd/\"\n",
    "\n",
    "    imdpath_val=\"/path/to/dir/Knee_MRI3/Femur/Val/\" + plane_view + \"/Imd/\"\n",
    "    pxdpath_val=\"/path/to/dir/Knee_MRI3/Femur/Val/\" + plane_view + \"/Pxd/\"\n",
    "    \n",
    "    imdpath_test=\"/path/to/dir/Knee_MRI3/Femur/Test/\" + plane_view + \"/Imd/\"\n",
    "    pxdpath_test=\"/path/to/dir/Knee_MRI3/Femur/Test/\" + plane_view + \"/Pxd/\"\n",
    "else:\n",
    "    imdpath=\"/mydata/Femur/Train/\" + plane_view + \"/Imd/\"\n",
    "    pxdpath=\"/mydata/Femur/Train/\" + plane_view + \"/Pxd/\"\n",
    "\n",
    "    imdpath_val=\"/mydata/Femur/Val/\" + plane_view + \"/Imd/\"\n",
    "    pxdpath_val=\"/mydata/Femur/Val/\" + plane_view + \"/Pxd/\"\n",
    "    \n",
    "    imdpath_test=\"/mydata/Femur/Test/\" + plane_view + \"/Imd/\"\n",
    "    pxdpath_test=\"/mydata/Femur/Test/\" + plane_view + \"/Pxd/\"\n",
    "    \n",
    "    !ls /mydata\n",
    "        \n",
    "\n",
    "# Get num_files in each directory\n",
    "num_files = get_num_files(pxdpath)\n",
    "num_files_val= get_num_files(pxdpath_val)\n",
    "num_files_test = get_num_files(pxdpath_test)\n",
    "print(num_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Session\n",
    "# Send it\n",
    "ct=0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Option to restore from model checkpoint to resume training\n",
    "    #saver.restore(sess, '/models/model_17055_Original')\n",
    "    \n",
    "    writer.add_graph(sess.graph)\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Reshuffle files every epoch\n",
    "        file_list=random_files(num_files)\n",
    "\n",
    "        i=0\n",
    "        print(\"EPOCH \" + \"{:d}\".format(epoch))\n",
    "        while i<num_files: # Assume batch_size = 1\n",
    "            \n",
    "            # Set up input\n",
    "            input_image=imageio.imread((imdpath + file_list[i] + '.png')) #Import slice\n",
    "            input_image=input_image-np.mean(input_image,axis=(0,1)) # Mean-center the slice\n",
    "            # image size must be divisible by 2^(depth)\n",
    "            input_image=fix_dims(input_image)\n",
    "            input_image=np.expand_dims(input_image,axis=2) # Expand image to have 3 axes --> [height, width, depth=1]\n",
    "            \n",
    "            picsize1=input_image.shape[0]\n",
    "            picsize2=input_image.shape[1] \n",
    "            bx=np.empty((batch_size,picsize1,picsize2,input_depth))\n",
    " \n",
    "            # Set up ground truth\n",
    "            ground=imageio.imread((pxdpath + file_list[i] + '.png'))\n",
    "            ground=fix_dims(ground)\n",
    "            ground=np.expand_dims(ground,axis=2) # Expand image to have 3 axes --> [height, width, depth=1]\n",
    "            by=np.empty((batch_size,picsize1,picsize2,num_classes))\n",
    "            \n",
    "            # randomly sample parameters for translation\n",
    "            x_stvs=15; y_stvs=15; \n",
    "            x_t=int(x_stvs*np.random.randn()); y_t=int(y_stvs*np.random.randn());\n",
    "            # randomly sample reflection flag\n",
    "            reflect_flag=np.random.binomial(1,0.5,1)\n",
    "            # Apply data augmentation (x and y translation and random y-axis reflection)\n",
    "            input_image_aug, ground_aug = random_translate_seg_version(input_image, ground, x_t, y_t, reflect_flag)\n",
    "            \n",
    "            # Reformat ground truth into one-hot\n",
    "            ground_one_hot = get_one_hot(ground_aug, num_classes)\n",
    "            \n",
    "            # Put input and ground into final format for flow graph [Batch, height, width, depth]\n",
    "            bx[0,:,:,:], by[0,:,:,:] = input_image_aug, ground_one_hot\n",
    "\n",
    "            # After setting up batch_x and batch_y, we can run train_op\n",
    "            sess.run(train_op,feed_dict={X: bx, Y: by})\n",
    "            loss, summary = sess.run([loss_op,summ],feed_dict={X: bx, Y: by})\n",
    "            writer.add_summary(summary, ct)\n",
    "\n",
    "            if i%display_step==0 or i==batch_size or i==0: \n",
    "                # Get metrics of interest and display\n",
    "                BC, DSC =sess.run([batch_confusion,dice], feed_dict={X: bx, Y: by})\n",
    "                print(BC)\n",
    "                print(\"Step \" + str(i) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Dice Similarity Coefficient = \" + \"{:.3f}\".format(DSC)) \n",
    "                \n",
    "                # Verify data by displaying ground truth with original image\n",
    "                f , (ax1, ax2) = plt.subplots(1,2,sharey=True, figsize=(6,2))\n",
    "                ax1.set_title(\"Slice\")\n",
    "                ax1.imshow(np.squeeze(bx[0,:,:,0]),cmap='gray')\n",
    "                ax2.imshow(np.squeeze(by[0,:,:,1]),cmap='gray')\n",
    "                ax2.set_title(\"Ground Truth\")\n",
    "                f.subplots_adjust(hspace=5.0)\n",
    "                plt.show()\n",
    "    \n",
    "            # Validation Step\n",
    "            if i%validation_step==0 and i>0: \n",
    "                dsc_vec_val=[];\n",
    "                ct_val=0;\n",
    "                \n",
    "                file_list_val=random_files(num_files_val)\n",
    "                for j in range(num_files_val): #Import data for that mini-batch\n",
    "                    \n",
    "                    # Set up validation input\n",
    "                    input_image=imageio.imread((imdpath_val + file_list_val[j] + '.png')) #Import slice\n",
    "                    input_image=input_image-np.mean(input_image,axis=(0,1)) # Mean-center the slice\n",
    "                    input_image=fix_dims(input_image)\n",
    "                    input_image=np.expand_dims(input_image,axis=2) # Expand image to have 3 axes --> [height, width, depth]\n",
    "        \n",
    "                    picsize1=input_image.shape[0]\n",
    "                    picsize2=input_image.shape[1] \n",
    "                    bx=np.empty((batch_size,picsize1,picsize2,input_depth))\n",
    "\n",
    "                    # Set up ground truth\n",
    "                    ground=imageio.imread((pxdpath_val + file_list_val[j] + '.png'))\n",
    "                    ground=fix_dims(ground)\n",
    "                    ground_one_hot=get_one_hot(ground,num_classes)\n",
    "                    by=np.empty((batch_size,picsize1,picsize2,num_classes))\n",
    "\n",
    "                    # No data augmentation for validation\n",
    "                    bx[0,:,:,:], by[0,:,:,:] = input_image, ground_one_hot \n",
    "\n",
    "                    DSC = sess.run(dice, feed_dict={X: bx, Y: by})\n",
    "                    dsc_vec_val.append(DSC)\n",
    "                \n",
    "                print(\"Validation Cohort Dice Similarity Coefficient = \" + \"{:.4f}\".format(np.mean(dsc_vec_val)) + \" (+-\" + \"{:.4f}\".format(np.std(dsc_vec_val)) + \")\")\n",
    "\n",
    "            #Save point    \n",
    "            if i%save_step==0:\n",
    "                s=''\n",
    "                checkpointnamelist=('./model_',str(ct),'_',plane_view)\n",
    "                checkpointname= s.join(checkpointnamelist)\n",
    "                save_path = saver.save(sess,checkpointname)\n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "            i=i+batch_size\n",
    "            ct=ct+batch_size\n",
    "\n",
    "print(\"We out here\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Session\n",
    "# Separate session for testing an image store on the trained model\n",
    "ct=0\n",
    "dsc_vec_test=[] # Vector to store dice similarity coefficient for each image\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, '/models/model_14175_Original') # Import trained model\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    file_list=random_files(num_files_test)\n",
    "    i=0\n",
    "    while i<num_files_test:   \n",
    "        # Set up validation input\n",
    "        input_image=imageio.imread((imdpath_test + file_list[i] + '.png')) #Import slice\n",
    "        input_image=input_image-np.mean(input_image,axis=(0,1)) # Mean-center the slice\n",
    "        input_image=fix_dims(input_image)\n",
    "        input_image=np.expand_dims(input_image,axis=2) # Expand image to have 3 axes --> [height, width, depth]\n",
    "\n",
    "        picsize1=input_image.shape[0]\n",
    "        picsize2=input_image.shape[1] \n",
    "        bx=np.empty((batch_size,picsize1,picsize2,input_depth))\n",
    "\n",
    "        # Set up ground truth\n",
    "        ground=imageio.imread((pxdpath_test + file_list[i] + '.png'))\n",
    "        ground=fix_dims(ground)\n",
    "        ground_one_hot=get_one_hot(ground,num_classes)\n",
    "        by=np.empty((batch_size,picsize1,picsize2,num_classes))\n",
    "\n",
    "        # No data augmentation for validation\n",
    "        bx[0,:,:,:], by[0,:,:,:] = input_image, ground_one_hot \n",
    "\n",
    "        # Get prediction and metrics\n",
    "        pred_out=sess.run(prediction,feed_dict={X: bx, Y: by})\n",
    "        DSC = sess.run(dice, feed_dict={X: bx, Y: by})\n",
    "        dsc_vec_test.append(DSC)\n",
    "\n",
    "        if i%10==0 or i==batch_size or i==0: \n",
    "\n",
    "            print(i)\n",
    "            f , (ax1, ax2,ax3) = plt.subplots(1,3,sharey=True, figsize=(9,3))\n",
    "\n",
    "            ax1.set_title(\"Slice\")\n",
    "            ax1.imshow(np.squeeze(bx[0,:,:,0]),cmap='gray')\n",
    "\n",
    "            ax2.set_title(\"Ground Truth\")\n",
    "            ax2.imshow(np.squeeze(by[0,:,:,1]),cmap='gray')\n",
    "\n",
    "            ax3.set_title(\"Prediction\")\n",
    "            ax3.imshow(np.squeeze(np.argmax(predout[0,:,:,:],axis=-1)),cmap='gray')\n",
    "\n",
    "            f.subplots_adjust(hspace=5.0)\n",
    "            plt.show()\n",
    "            trainstep_actual+=trainstep_actual\n",
    "            print(\"Dice Similarity Coefficient = \" + \"{:.4f}\".format(DSC))\n",
    "\n",
    "        i=i+batch_size\n",
    "        ct=ct+batch_size\n",
    "        \n",
    "    print(\"Test Cohort Dice Similarity Coefficient = \" + \"{:.4f}\".format(np.mean(dsc_vec_test)) + \" (+-\" + \"{:.4f}\".format(np.std(dsc_vec_test)) + \")\")\n",
    "\n",
    "\n",
    "print(\"We out here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Session\n",
    "# Separate session for inferring the model on each subject\n",
    "ct=0\n",
    "dsc_vec_test=[] # Vector to store dice similarity coefficient for each image\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, '/models/model_14175_Original') # Import trained model\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    file_list=random_files(num_files_test)\n",
    "    \n",
    "    #Get num subjects\n",
    "    if mode=='j':\n",
    "        directory='/path/to/dir/Knee_MRI3/Femur/Inference/'\n",
    "    else:\n",
    "        directory='/mydata/Femur/Inference/'\n",
    "    num_subj=int(len(glob.glob(directory + \"*/\")))\n",
    "    \n",
    "    for kk in range(num_subj):\n",
    "        #get num slices for this subject\n",
    "        subj_dir=directory + str(kk+1) + '/'\n",
    "        num_slices=int(len(glob.glob(subj_dir + \"*.png\")))\n",
    "        print(str(num_slices) + ' slices for subject ' + str(kk_1))\n",
    "        \n",
    "        # Make directory for this subject\n",
    "        #inference/subject/plane/Inf\n",
    "        pathout='/Inference/' + str(kk+1) + '/' + plane_view + '/Inf/'\n",
    "        os.mkdir(pathout)\n",
    "        \n",
    "        i=0\n",
    "        while i<num_slices: \n",
    "            fileID=str(i)\n",
    "            IDlength=6\n",
    "            while len(fileID)<IDlength:\n",
    "                fileID='0'+fileID\n",
    "            \n",
    "            # Set up input\n",
    "            input_image=imageio.imread((imdpath_test + fileID + '.png')) #Import slice\n",
    "            input_image=input_image-np.mean(input_image,axis=(0,1)) # Mean-center the slice\n",
    "            original_dims=np.array(input_image).shape\n",
    "            input_image=fix_dims(input_image)\n",
    "            input_image=np.expand_dims(input_image,axis=2) # Expand image to have 2 axes --> [height, width, depth]\n",
    "\n",
    "            picsize1=input_image.shape[0]\n",
    "            picsize2=input_image.shape[1] \n",
    "            bx=np.empty((batch_size,picsize1,picsize2,input_depth))\n",
    "            \n",
    "            # No data augmentation\n",
    "            bx[0,:,:,:] = input_image\n",
    "\n",
    "            # Get prediction\n",
    "            probability_map=sess.run(prediction,feed_dict={X: bx})\n",
    "            \n",
    "            # Probability map is one-hot, we want the dimension that corresponds to landmark probability (not background)\n",
    "            imageio.imwrite(pathout + fileID + \".png\",np.squeeze(predout[0,:original_dims[0],:original_dims[1],1]))\n",
    "\n",
    "            i=i+1\n",
    "            ct=ct+1\n",
    "\n",
    "print(\"We out here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
