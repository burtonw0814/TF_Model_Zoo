{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal here is to import a graph of a trained U-Net architecture, restrict the gradient flow through \n",
    "# this trained architecture, \n",
    "# and build a convLSTM architecture off of the imported graph.\n",
    "\n",
    "#Relevant Papers:\n",
    "    # U-Net -->  \n",
    "        #Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation.\n",
    "    \n",
    "    # convLSTM --> \n",
    "        # Xingjian SH, Chen Z, Wang H, Yeung DY, Wong WK, Woo WC. Convolutional LSTM network: A machine learning approach for precipitation nowcasting. \n",
    "    \n",
    "    # BDC-LSTM for Segmentation --> \n",
    "        #Chen J, Yang L, Zhang Y, Alber M, Chen DZ. Combining fully convolutional and recurrent neural networks for 3d biomedical image segmentation.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of .png files in path\n",
    "def get_num_files(path_ground):\n",
    "\n",
    "    ground_files=glob.glob(path_ground + \"*.png\")\n",
    "    num_files=int(len(glob.glob(path_ground + \"*.png\")))\n",
    "    \n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dims(image):\n",
    "    image=np.array(image)\n",
    "    depth=4\n",
    "    \n",
    "    #Start with dim 1\n",
    "    if image.shape[1]%(2**depth)!=0:\n",
    "        lb=int(image.shape[1]/(2**depth))\n",
    "        while image.shape[1]<((2**depth)*(lb+1)):\n",
    "            image=np.concatenate((image,np.zeros((image.shape[0],1,image.shape[2],image.shape[3]))),axis=1)\n",
    "\n",
    "    if image.shape[2]%(2**depth)!=0:\n",
    "        lb=int(image.shape[2]/(2**depth))\n",
    "        while image.shape[2]<((2**depth)*(lb+1)):\n",
    "            image=np.concatenate((image,np.zeros((image.shape[0],image.shape[1],1,image.shape[3]))),axis=2)\n",
    "                    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_translate_seg_version(input_block,ground_truth_block,y_dir,x_dir,reflect_flag):\n",
    "    # Input_block is [height, width, depth=1]\n",
    "    # Ground_truth_block is [height, width, depth=1]\n",
    "    \n",
    "    imsize=input_block.shape\n",
    "    temp=np.empty((imsize[0],imsize[1],imsize[2]))\n",
    "    temp_ground=np.empty((imsize[0],imsize[1],imsize[2]))\n",
    "    y_abs=np.absolute(y_dir)\n",
    "    x_abs=np.absolute(x_dir)\n",
    "    \n",
    "    # Reflection about y-axis (width)\n",
    "    if reflect_flag==1:\n",
    "        input_block=np.flip(input_block,1)\n",
    "        ground_truth_block=np.flip(ground_truth_block,1)        \n",
    "    \n",
    "    # Vertical translation\n",
    "    if y_dir != 0: \n",
    "        height_pad=np.zeros((y_abs,imsize[1],imsize[2]))\n",
    "        if y_dir>0: # Shift up --> attach zeros to bottom\n",
    "            temp=np.concatenate((input_block[y_abs:,:,:],height_pad),axis=0)\n",
    "            temp_ground=np.concatenate((ground_truth_block[y_abs:,:,:],height_pad),axis=0)\n",
    "        else: # Shift down --> attach zeros to top\n",
    "            temp=np.concatenate((height_pad,input_block[:(-1*y_abs),:,:]),axis=0)\n",
    "            temp_ground=np.concatenate((height_pad,ground_truth_block[:(-1*y_abs),:,:]),axis=0)\n",
    "    else: \n",
    "        temp=input_block\n",
    "        temp_ground=ground_truth_block\n",
    "        \n",
    "    # Horizontal translation\n",
    "    if x_dir!=0:\n",
    "        width_pad=np.zeros((imsize[0],x_abs,imsize[2]))\n",
    "        if x_dir>0:\n",
    "            temp2=np.concatenate((width_pad,temp[:,:(-1*x_abs),:]),axis=1)\n",
    "            temp2_ground=np.concatenate((width_pad,temp_ground[:,:(-1*x_abs),:]),axis=1)\n",
    "        else: \n",
    "            temp2=np.concatenate((temp[:,x_abs:,:],width_pad),axis=1)\n",
    "            temp2_ground=np.concatenate((temp_ground[:,x_abs:,:],width_pad),axis=1)\n",
    "    else:\n",
    "        temp2=temp\n",
    "        temp2_ground=temp_ground\n",
    "        \n",
    "    # Returns tensors with same dimensions as the inputs\n",
    "    return temp2, temp2_ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_files(num_files):\n",
    "    x = ([[i] for i in range(num_files)])\n",
    "    shuflist=random.sample(x,len(x))\n",
    "    list_files=[]\n",
    "\n",
    "    s=''\n",
    "    for i in range(num_files):\n",
    "        ID=str(shuflist[i][0])\n",
    "        while len(ID)<6:\n",
    "            ID='0'+ID\n",
    "        list_files.append(ID)\n",
    "            \n",
    "    return list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer wrappers\n",
    "def conv_layer(inputs, channels_in, channels_out, stvs, strides=1, scopename=\"Conv\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        s=''\n",
    "        weightname=(scopename,'_weights')\n",
    "        biasname=(scopename,'_bias')\n",
    "        \n",
    "        w=tf.Variable(tf.random_normal([3, 3, channels_in, channels_out],stddev=stvs),name=s.join(weightname))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        \n",
    "        b=tf.Variable(tf.random_normal([channels_out],stddev=stvs),name=s.join(biasname))\n",
    "        tf.summary.histogram((\"Weight\" + scopename),w)\n",
    "        tf.summary.histogram((\"Bias\" + scopename),b)\n",
    "        \n",
    "        x = tf.nn.conv2d(inputs, w, strides=[1, strides, strides, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        #x=tf.contrib.layers.layer_norm(x)\n",
    "        epsilon = 1e-3\n",
    "        scale = tf.Variable(tf.ones([x.get_shape()[-1]]))\n",
    "        beta = tf.Variable(tf.zeros([x.get_shape()[-1]]))\n",
    "        batch_mean, batch_var = tf.nn.moments(x,[1,2],keep_dims=True)\n",
    "        x=tf.nn.batch_normalization(x, batch_mean, batch_var, beta, scale, epsilon)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2, scopename=\"Pool\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "\n",
    "def upconv2d(x, channels_in, channels_out, stvs, stride=2, scopename=\"Upconv\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        w=tf.Variable(tf.random_normal([2, 2, channels_out, channels_in],stddev=stvs))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        \n",
    "        x_shape = tf.shape(x)\n",
    "        output_shape = tf.stack([x_shape[0], x_shape[1]*2, x_shape[2]*2, x_shape[3]//2]) # [BS doubleheight doubl width  halvedepth]\n",
    "        return tf.nn.conv2d_transpose(x, w, output_shape, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def concatenate(in1, in2, scopename=\"Concat\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        return tf.concat([in1, in2], 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlstm_wrapper(x, trunc_prop, depthstart, cell_state, hidden_state, cell_state_in, hidden_state_in, scopename, cellname):\n",
    "\n",
    "    with tf.name_scope(scopename):\n",
    "        \n",
    "        cell_state_temp_in = tf.placeholder(tf.float32, [1, None, None, depthstart]) # Consistent with input dimensions\n",
    "        hidden_state_temp_in = tf.placeholder(tf.float32, [1, None, None, depthstart]) # Consistent with input dimensions\n",
    "        \n",
    "        cell_state_in.append(cell_state_temp_in)\n",
    "        hidden_state_in.append(hidden_state_temp_in)\n",
    "        \n",
    "        # Initialize output tensor list\n",
    "        out_list=[];\n",
    "        \n",
    "        # Define convolutional parameters \n",
    "        # Don't use peepholes for variable input dims, and dont use skip connections for now\n",
    "        strides=1; forget_bias=1; s='';\n",
    "        w=tf.Variable(tf.random_normal([3, 3, depthstart*2, depthstart*4],stddev=0.01), name=s.join(\"Weights_\"+scopename))\n",
    "        tf.add_to_collection(\"New_Vars\", w)\n",
    "        # tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        b=tf.Variable(tf.random_normal([depthstart*4],stddev=0.01),name=s.join(\"Bias_\"+scopename))\n",
    "        tf.add_to_collection(\"New_Vars\", b)\n",
    "        \n",
    "        hidden_state_temp=hidden_state_temp_in\n",
    "        cell_state_temp=cell_state_temp_in \n",
    "        \n",
    "        for j in range(trunc_prop):\n",
    "            \n",
    "            feature_block = tf.concat([x[j], hidden_state_temp], 3)\n",
    "            feature_block = tf.nn.conv2d(feature_block, w, strides=[1, strides, strides, 1], padding='SAME')\n",
    "            feature_block = tf.nn.bias_add(feature_block, b)\n",
    "            \n",
    "            input_gate, new_input, forget_gate, output_gate = tf.split(feature_block , 4, axis=-1)\n",
    "            \n",
    "            new_cell = tf.nn.sigmoid(forget_gate+forget_bias) * cell_state_temp\n",
    "            new_cell += tf.nn.sigmoid(input_gate) * tf.nn.tanh(new_input)\n",
    "            \n",
    "            out = tf.nn.sigmoid(output_gate) * tf.nn.tanh(new_cell)\n",
    "            \n",
    "            hidden_state_temp = out\n",
    "            cell_state_temp = new_cell\n",
    "            \n",
    "            # Append out tensor for this time list\n",
    "            out_list.append(out)\n",
    "           \n",
    "        # Need to store cell_state and hidden_state for next go round\n",
    "        # also hidden state is the out!\n",
    "        cell_state.append(cell_state_temp)\n",
    "        hidden_state.append(hidden_state_temp)\n",
    "        \n",
    "        # out_list is a list of length [trunc_prop] tensors of the hidden_states at each time step. \n",
    "        # We also want to store the latest hidden_state and cell_state to use for the next trunc_prop iteration\n",
    "        return out_list, cell_state, hidden_state, cell_state_in, hidden_state_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of network\n",
    "def conv_net(inputdepth, trunc_prop, path_to_trained_model):\n",
    "    stvs=0.01\n",
    "    depthstart=64\n",
    "    num_classes=2\n",
    "    \n",
    "    #Import meta_graph\n",
    "    print(\"Importing from \" + path_to_trained_model + \".meta\")\n",
    "    transfer_saver=tf.train.import_meta_graph((path_to_trained_model + '.meta'))\n",
    "    \n",
    "    new_graph = tf.get_default_graph()\n",
    "    \n",
    "    # Identify input node from imported graph\n",
    "    X = new_graph.get_tensor_by_name('Input/Placeholder:0')\n",
    "    Y = new_graph.get_tensor_by_name('Ground_Truth/Placeholder:0')\n",
    "    \n",
    "    #Identify final conv block tensor of imported graph \n",
    "    conv9b = new_graph.get_tensor_by_name('conv9b/Relu:0')\n",
    "    \n",
    "    #Identify supplemental output from flow graph\n",
    "    #softmax_supp = new_graph.get_tensor_by_name('Softmax/Reshape_1:0')\n",
    "    \n",
    "    #pred_for_plot=tf.split(tf.argmax(softmax_supp, axis=3), trunc_prop, axis=0)   \n",
    "    #for kk in range(trunc_prop):\n",
    "    #    tf.summary.image(('Supp_Predict'+ str(kk)), tf.cast(tf.expand_dims(pred_for_plot[kk], 3),tf.float32), inputdepth)\n",
    "    \n",
    "    # Cut gradient flow\n",
    "    conv9b_sg = tf.stop_gradient(conv9b)  # Conv9b is in format [trunc_prop as BS, height, width, depth]\n",
    "    print(conv9b_sg)\n",
    "    \n",
    "    # Now augment the CLSTM component to the graph\n",
    "    x=tf.expand_dims(conv9b_sg,axis=0) #Now it is [BS, trunc_prop, height, width, depth]\n",
    "    unstack=tf.unstack(x,trunc_prop,axis=1)\n",
    "    \n",
    "    # Initilize list of hidden and cell states and states -- \n",
    "    # This list is for keeping track of cell_state, hidden_state for each ConvLSTM that is called in the network\n",
    "    # One list for current cell and hidden states and one list for the pointers to input placeholders for the flow graph\n",
    "    cell_state=[]; hidden_state=[]; \n",
    "    cell_state_in=[]; hidden_state_in=[];\n",
    "\n",
    "    scopename=\"CLSTM1\"\n",
    "    cellname=\"Cell1\"\n",
    "    with tf.name_scope(scopename):\n",
    "        outputs, cell_state, hidden_state, cell_state_in, hidden_state_in = convlstm_wrapper(unstack, trunc_prop, depthstart, cell_state, hidden_state, cell_state_in, hidden_state_in, scopename, cellname)\n",
    "        # states.append(states_temp); cell_state.append(cell_state_temp); hidden_state.append(hidden_state_temp)\n",
    "    \n",
    "    scopename=\"CLSTM2\"\n",
    "    cellname=\"Cell2\"\n",
    "    with tf.name_scope(scopename):\n",
    "        outputs, cell_state, hidden_state, cell_state_in, hidden_state_in=convlstm_wrapper(outputs, trunc_prop, depthstart, cell_state, hidden_state, cell_state_in, hidden_state_in, scopename, cellname)\n",
    "        # states.append(states_temp); cell_state.append(cell_state_temp); hidden_state.append(hidden_state_temp)\n",
    "        \n",
    "        # Concatenate the list of time steps back into batch mode --> [trunc_prop as batch, height, width, depth]\n",
    "        out_map=tf.concat(outputs,0)\n",
    "        \n",
    "    out_map2=concatenate(conv9b_sg,out_map,scopename=\"concat_final\")   \n",
    "    print(out_map2)\n",
    "         \n",
    "    # Reduce depth to num_classes\n",
    "    with tf.name_scope(\"Logs_CLSTM\"):\n",
    "        w=tf.Variable(tf.random_normal([1, 1, depthstart*2, num_classes], stddev=stvs))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        tf.add_to_collection(\"New_Vars\", w)\n",
    "        \n",
    "        b=tf.Variable(tf.random_normal([num_classes],stddev=stvs))\n",
    "        tf.add_to_collection(\"New_Vars\", b)\n",
    "\n",
    "        loglayer = tf.nn.conv2d(out_map2, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        loglayer = tf.nn.bias_add(loglayer,b)\n",
    "        \n",
    "    return loglayer, cell_state, hidden_state, cell_state_in, hidden_state_in, X, Y, transfer_saver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice loss function -- Defined according to the V-net paper by Milletari et al\n",
    "def dice_loss(logits, onehot_labels):\n",
    "    with tf.name_scope(\"Dice_Loss_CLSTM\"):\n",
    "\n",
    "        eps = 1e-5\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "        intersection = tf.reduce_sum(prediction * onehot_labels)\n",
    "        union =  eps + tf.reduce_sum(prediction) + tf.reduce_sum(onehot_labels)\n",
    "        dice_loss = -(2 * intersection/ (union))\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(image, num_classes): # Image is an [m  n] atrix\n",
    "    \n",
    "    # Make sure ground truth image is either 0 or 1, not 0 or 255\n",
    "    if np.amax(image>0):\n",
    "        image=np.divide(image,np.amax(image))\n",
    "    image=image.astype(int)\n",
    "    \n",
    "    b=np.zeros((image.shape[0],image.shape[1],num_classes))\n",
    "    #for kk in range(image.shape[0]):\n",
    "    #    for jj in range(image.shape[1]):\n",
    "    #        #b[kk, range(image.shape[1]), image[kk,:]]=1\n",
    "    #        b[kk, jj, image[kk,jj]]=1\n",
    "    \n",
    "    b[:, :, 1]=image\n",
    "    b[:, :, 0]=np.abs(image-1)\n",
    "    \n",
    "    # b is the one-hot version of image with dimensions [m n num_classes]\n",
    "    return b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(input_depth, num_classes, trunc_prop, path_to_model):\n",
    "    \n",
    "    #with tf.name_scope(\"Ground_Truth\"):\n",
    "    #    Y = tf.placeholder(tf.float32, [None, None, None, num_classes])\n",
    "    \n",
    "    # Define flow graph\n",
    "    logits, cell_state, hidden_state, cell_state_in, hidden_state_in, X, Y, transfer_saver = conv_net(input_depth, trunc_prop, path_to_model)\n",
    "\n",
    "    # Prediction function for evaluating accuracy\n",
    "    with tf.name_scope(\"Softmax_CLSTM\"):\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Define Loss\n",
    "    with tf.name_scope(\"Loss_CLSTM\"):\n",
    "        loss_op=dice_loss(logits,Y)\n",
    "        #regularizer = tf.contrib.layers.l2_regularizer(scale=0.0001)\n",
    "        #reg_variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        #reg_term = tf.contrib.layers.apply_regularization(regularizer, reg_variables)\n",
    "        #loss_op += reg_term\n",
    "        tf.summary.scalar(\"Loss_CLSTM\",loss_op)\n",
    "\n",
    "    # Define optimizer\n",
    "    with tf.name_scope(\"Optimizer_CLSTM\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)    \n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "        \n",
    "    with tf.name_scope(\"Metrics_CLSTM\"):\n",
    "        # Dice similarity coefficient\n",
    "        eps = 1e-5\n",
    "        intersection = tf.reduce_sum(prediction * Y)\n",
    "        union =  eps + tf.reduce_sum(prediction) + tf.reduce_sum(Y)\n",
    "        dice = (2 * intersection/ (union))\n",
    "        tf.summary.scalar(\"Dice_Similarity_Coefficient_CLSTM\",dice)\n",
    "\n",
    "        # IoU\n",
    "        #iou=tf.metrics.mean_iou(Y,prediction,num_classes)\n",
    "        #tf.summary.scalar(\"IoU\",iou)\n",
    "        \n",
    "        # Images for TensorBoard\n",
    "        #logs_for_plot=tf.split(tf.argmax(logits ,axis=3), 4, axis=-1)\n",
    "        #ground_for_plot=tf.split(tf.argmax(Y ,axis=3), 4, axis=-1)\n",
    "        #slice_for_plot=tf.split(X, 4, axis=-1)\n",
    "        \n",
    "        # Images for TensorBoard\n",
    "        logs_for_plot=tf.split(tf.argmax(logits ,axis=3), trunc_prop, axis=0)\n",
    "        ground_for_plot=tf.split(tf.argmax(Y ,axis=3),  trunc_prop, axis=0)\n",
    "        slice_for_plot=tf.split(X,  trunc_prop, axis=0)\n",
    "        \n",
    "        for kk in range(trunc_prop):\n",
    "            tf.summary.image(('Predict'+ str(kk) + \"_CLSTM\"), tf.cast(tf.expand_dims(logs_for_plot[kk], 3),tf.float32), input_depth)\n",
    "            tf.summary.image(('Ground'+ str(kk) + \"_CLSTM\"), tf.cast(tf.expand_dims( ground_for_plot[kk], 3),tf.float32), input_depth) \n",
    "            tf.summary.image(('Slice'+ str(kk) + \"_CLSTM\"), tf.cast(slice_for_plot[kk],tf.float32), input_depth)  \n",
    "        \n",
    "        # Confusion Matrix\n",
    "        batch_confusion = tf.confusion_matrix(tf.reshape(tf.argmax(Y,axis=3),[-1]),tf.reshape(tf.argmax(prediction,axis=3),[-1]),num_classes=num_classes,name='Batch_confusion_CLSTM')\n",
    "\n",
    "    # Define writer for Tensorboard\n",
    "    writer=tf.summary.FileWriter(\"/output/1\")\n",
    "    summ=tf.summary.merge_all()\n",
    "\n",
    "    # Initialize the variables\n",
    "    #init = tf.global_variables_initializer()\n",
    "    init_new_vars = tf.variables_initializer(tf.get_collection(\"New_Vars\"))\n",
    "\n",
    "    #Define saver for model saver\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    return X, Y, cell_state, hidden_state, cell_state_in, hidden_state_in, logits, prediction, loss_op, train_op, batch_confusion, dice, writer, summ, init_new_vars, saver, transfer_saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set hyperparameters, etc.\n",
    "learning_rate = 0.00001\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 1\n",
    "input_depth = 1\n",
    "num_classes = 2 \n",
    "\n",
    "display_step = 480\n",
    "validation_step = 480\n",
    "save_step = 960\n",
    "trunc_prop= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some flags\n",
    "mode='j'\n",
    "plane_view='Sagittal';\n",
    "#plane_view='Coronal';\n",
    "#plane_view='Transverse';\n",
    "if plane_view=='Sagittal':\n",
    "    x_stvs=15; y_stvs=15; \n",
    "else:\n",
    "    x_stvs=5; y_stvs=5; \n",
    "\n",
    "\n",
    "\n",
    "# Distinguish paths between running on local notebook vs. running in the cloud\n",
    "if mode=='j':    \n",
    "    imdpath=\"/path/to/dir/Knee_MRI4/Femur/Train/\" + plane_view + \"/\"\n",
    "    pxdpath=\"/path/to/dir/Knee_MRI4/Femur/Train/\" + plane_view + \"/\"\n",
    "\n",
    "    imdpath_val=\"/path/to/dir/Knee_MRI4/Femur/Val/\" + plane_view + \"/\"\n",
    "    pxdpath_val=\"/path/to/dir/Knee_MRI4/Femur/Val/\" + plane_view + \"/\"\n",
    "    \n",
    "    imdpath_test=\"/path/to/dir/Knee_MRI4/Femur/Test/\" + plane_view + \"/\"\n",
    "    pxdpath_test=\"/path/to/dir/Knee_MRI4/Femur/Test/\" + plane_view + \"/\"\n",
    "    \n",
    "    # Local path to trained U-Net Architecture onto which the recurrent components are augmented\n",
    "    path_to_model=\"/path/to/dir/model_16095_Original\"\n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    imdpath=\"/mydata/Femur/Train/\" + plane_view + \"/\"\n",
    "    pxdpath=\"/mydata/Femur/Train/\" + plane_view + \"/\"\n",
    "\n",
    "    imdpath_val=\"/mydata/Femur/Val/\" + plane_view + \"/\"\n",
    "    pxdpath_val=\"/mydata/Femur/Val/\" + plane_view + \"/\"\n",
    "    \n",
    "    imdpath_test=\"/mydata/Femur/Test/\" + plane_view + \"/\"\n",
    "    pxdpath_test=\"/mydata/Femur/Test/\" + plane_view + \"/\"\n",
    "    \n",
    "    # Path to trained U-Net Architecture onto which the recurrent components are augmented\n",
    "    path_to_model=\"/models/model_4720_Sagittal\"\n",
    "    \n",
    "    !ls /mydata\n",
    "       \n",
    "train_mode=True\n",
    "tf.reset_default_graph()\n",
    "X, Y, cell_state, hidden_state, cell_state_in, hidden_state_in, logits, prediction, loss_op, train_op, batch_confusion, dice, writer, summ, init_new_vars, saver, transfer_saver = build_graph(input_depth, num_classes, trunc_prop, path_to_model)\n",
    "    \n",
    "num_subj_train=20; num_subj_val=2; num_subj_test=5;       \n",
    "# Get num_files in each directory\n",
    "#num_files = get_num_files(pxdpath)\n",
    "#num_files_val= get_num_files(pxdpath_val)\n",
    "#num_files_test = get_num_files(pxdpath_test)\n",
    "#print(num_files)\n",
    "\n",
    "\n",
    "# And lastly, get weights from original graph so you can make sure they aren't actually training\n",
    "#check_weight = tf.get_variable(\"conv1b/Variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pics(path):\n",
    "    \n",
    "    num_files=int(len(glob.glob(path + '*.png')))\n",
    "    file_list=random_files(num_files)\n",
    "    image=imageio.imread((path + file_list[0] + '.png')) #Import slice\n",
    "    picsize1=image.shape[0]; picsize2=image.shape[1] \n",
    "    images=np.empty((num_files,picsize1,picsize2,1))\n",
    "    \n",
    "    for i in range(num_files):\n",
    "        ID=str(i)\n",
    "        while len(ID)<6:\n",
    "            ID='0'+ID\n",
    "        images[i,:,:,0]=imageio.imread((path + ID + '.png')) #Import slice\n",
    "    #Return 4d tensor    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Session\n",
    "# Send it\n",
    "ct = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #sess.run(init)\n",
    "    #Option to restore from model checkpoint to resume training\n",
    "    #saver.restore(sess, '/models/model_17055_Original')\n",
    "    \n",
    "    # Import variables from trained U-Net\n",
    "    # transfer_saver.restore(sess, (path_to_model + '.data-00000-of-00001'))\n",
    "    transfer_saver.restore(sess, (path_to_model))\n",
    "    \n",
    "    #Initialize the rest of the variables\n",
    "    sess.run(init_new_vars)\n",
    "    \n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"EPOCH \" + \"{:d}\".format(epoch))\n",
    "        \n",
    "        for subj in range(1,1+num_subj_train):\n",
    "            \n",
    "            #dsc_vec=[]; slice_vec=[];\n",
    "            \n",
    "            print(\"Subject \" + str(subj))\n",
    "            \n",
    "            # Get stack of inputs -- Returns 4d tensor\n",
    "            images=get_pics((imdpath  + str(subj) + '/Imd/'))\n",
    "            images=images-np.mean(images)\n",
    "\n",
    "            # Get stack of outputs -- Returns 4d tensor\n",
    "            grounds=get_pics((pxdpath  + str(subj) + '/Pxd/'))\n",
    "            \n",
    "            images=fix_dims(images)\n",
    "            grounds=fix_dims(grounds)\n",
    "            \n",
    "            # Randomly sample parameters for translation\n",
    "            x_t=int(x_stvs*np.random.randn()); y_t=int(y_stvs*np.random.randn());\n",
    "            # Randomly sample reflection flag\n",
    "            reflect_flag=np.random.binomial(1,0.5,1)\n",
    "            \n",
    "            bxx=np.empty((images.shape[0],images.shape[1],images.shape[2],1)) # Intialize np matrix to hold all images\n",
    "            byy=np.empty((grounds.shape[0],grounds.shape[1],grounds.shape[2],num_classes)) # Intialize np matrix to hold all images\n",
    "            for j in range(images.shape[0]): # Apply translations to all images\n",
    "                images[j,:,:,:], grounds[j,:,:,:] = random_translate_seg_version(images[j,:,:,:],grounds[j,:,:,:],x_t,y_t,reflect_flag)\n",
    "            \n",
    "            for j in range(images.shape[0]): # One-hot\n",
    "                byy[j,:,:,:] = get_one_hot(grounds[j,:,:,0], num_classes)\n",
    "                bxx[j,:,:,:] = images[j,:,:,:]\n",
    "            \n",
    "            # Initialize cell and hidden for this subject\n",
    "            current_cell=[]; current_hidden=[];\n",
    "            for kk in range(2):\n",
    "                current_cell.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "                current_hidden.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "                         \n",
    "            i=0\n",
    "            # Because we are using a static_rnn, iterate through the subject [trunc_prop] slices at a time\n",
    "            while i+trunc_prop<=images.shape[0]:\n",
    "                bx=np.empty((trunc_prop, bxx.shape[1], bxx.shape[2], input_depth))\n",
    "                by=np.empty((trunc_prop, bxx.shape[1], bxx.shape[2], num_classes))\n",
    "\n",
    "                bx=bxx[i:i+trunc_prop,:,:,:] #Bx gets all the images in that batch\n",
    "                by=byy[i:i+trunc_prop,:,:,:]     \n",
    "                #by[0,:,:,:]=byy[i+trunc_prop-1,:,:,:] #By gets only last image\n",
    "                \n",
    "                if epoch > 0 or np.max(by[:,:,:,1])>0: #Only train on positive examples for the first epoch\n",
    "           \n",
    "                    # sess.run(train_op,feed_dict={X: bx, Y: by, cell_state[0]: current_cell[0], hidden_state[0]: current_hidden[0], cell_state[1]: current_cell[1], hidden_state[1]: current_hidden[1],cell_state[2]: current_cell[2], hidden_state[2]: current_hidden[2],cell_state[3]: current_cell[3], hidden_state[3]: current_hidden[3]})\n",
    "                    sess.run(train_op,feed_dict={X: bx, Y: by, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "\n",
    "                    # loss, acc, summary, pred=sess.run([loss_op,accuracy,summ,prediction],feed_dict={X: bx, Y: by, cell_state[0]: current_cell[0], hidden_state[0]: current_hidden[0],cell_state[1]: current_cell[1], hidden_state[1]: current_hidden[1],cell_state[2]: current_cell[2], hidden_state[2]: current_hidden[2],cell_state[3]: current_cell[3], hidden_state[3]: current_hidden[3]})\n",
    "                    DSC, summary = sess.run([dice, summ],feed_dict={X: bx, Y: by, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "\n",
    "                    writer.add_summary(summary, ct)\n",
    "                \n",
    "                # After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "                current_cell, current_hidden = sess.run([cell_state, hidden_state],feed_dict={X: bx, Y: by, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "\n",
    "\n",
    "                if i==30:\n",
    "                    # Verify data by displaying ground truth with original image that it is trying to predict\n",
    "                    f , (ax1, ax2) = plt.subplots(1,2,sharey=True, figsize=(6,2))\n",
    "                    ax1.set_title(\"Slice\")\n",
    "                    ax1.imshow(np.squeeze(bx[-1,:,:,0]),cmap='gray')\n",
    "                    ax2.imshow(np.squeeze(by[-1,:,:,1]),cmap='gray')\n",
    "                    ax2.set_title(\"Ground Truth\")\n",
    "                    f.subplots_adjust(hspace=5.0)\n",
    "                    plt.show()\n",
    "                    \n",
    "                    #plt.plot(prediction_vec,'r',logits_vec,'g',ground_vec,'k--')\n",
    "                    #plt.ylabel('Subject Predictions')\n",
    "                    #plt.show()\n",
    "\n",
    "                i+=trunc_prop\n",
    "                ct+=trunc_prop\n",
    "                         \n",
    "            # VALIDATION\n",
    "            if subj>0 and subj%20==0:  \n",
    "                s=''\n",
    "                checkpointnamelist=('./model_',str(ct),'_',plane_view,'_CLSTM')\n",
    "                checkpointname= s.join(checkpointnamelist)\n",
    "                save_path = saver.save(sess,checkpointname)\n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "                                 \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                for subj_val in range(1,1+num_subj_val):\n",
    "                    DSC_val_vec=[];\n",
    "                    print(\"Validation Subject \" + str(subj_val))\n",
    "                         \n",
    "                    # Get stack of inputs -- Returns 4d tensor\n",
    "                    images=get_pics((imdpath_val  + str(subj_val) + '/Imd/'))\n",
    "                    images=images-np.mean(images)\n",
    "                    # Get stack of outputs -- Returns 4d tensor\n",
    "                    grounds=get_pics((pxdpath_val  + str(subj_val) + '/Pxd/'))\n",
    "\n",
    "                    images=fix_dims(images)\n",
    "                    grounds=fix_dims(grounds)\n",
    "\n",
    "                    bxx=np.empty((images.shape[0],images.shape[1],images.shape[2],1)) # Intialize np matrix to hold all images\n",
    "                    byy=np.empty((grounds.shape[0],grounds.shape[1],grounds.shape[2],num_classes)) # Intialize np matrix to hold all images\n",
    "                  \n",
    "                    for j in range(images.shape[0]): # One-hot \n",
    "                        byy[j,:,:,:] = get_one_hot(grounds[j,:,:,0], num_classes)\n",
    "                        bxx[j,:,:,:] = images[j,:,:,:]\n",
    "\n",
    "                    # Initialize cell and hidden for this subject\n",
    "                    current_cell=[]; current_hidden=[];\n",
    "                    for kk in range(2):\n",
    "                        current_cell.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "                        current_hidden.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "\n",
    "                    i=0\n",
    "                    # Because we are using a static_rnn, iterate through the subject [trunc_prop] slices at a time\n",
    "                    while i+trunc_prop<=images.shape[0]:\n",
    "                        bx=np.empty((trunc_prop, bxx.shape[1], bxx.shape[2], input_depth))\n",
    "                        by=np.empty((trunc_prop, bxx.shape[1], bxx.shape[2], num_classes))\n",
    "\n",
    "                        bx=bxx[i:i+trunc_prop,:,:,:] # Bx gets all the images in that batch\n",
    "                        by=byy[i:i+trunc_prop,:,:,:]     \n",
    "                        #by[0,:,:,:]=byy[i+trunc_prop-1,:,:,:] #By gets only last image\n",
    "\n",
    "                        # loss, acc, summary, pred=sess.run([loss_op,accuracy,summ,prediction],feed_dict={X: bx, Y: by, cell_state[0]: current_cell[0], hidden_state[0]: current_hidden[0],cell_state[1]: current_cell[1], hidden_state[1]: current_hidden[1],cell_state[2]: current_cell[2], hidden_state[2]: current_hidden[2],cell_state[3]: current_cell[3], hidden_state[3]: current_hidden[3]})\n",
    "                        DSC=sess.run(dice,feed_dict={X: bx, Y: by, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "                        DSC_val_vec.append(DSC)\n",
    "                        \n",
    "                         # After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "                        current_cell, current_hidden =sess.run([cell_state, hidden_state],feed_dict={X: bx, Y: by, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "\n",
    "                        # Unpack the state\n",
    "                        # For kk in range(len(current_hidden)):\n",
    "                        #    Current_cell[kk], current_hidden[kk] = current_total[kk]\n",
    "\n",
    "                        if i==30:\n",
    "                            #Verify data by displaying ground truth with original image that it is trying to predict\n",
    "                            f , (ax1, ax2) = plt.subplots(1,2,sharey=True, figsize=(6,2))\n",
    "                            ax1.set_title(\"Slice\")\n",
    "                            ax1.imshow(np.squeeze(bx[-1,:,:,0]),cmap='gray')\n",
    "                            ax2.imshow(np.squeeze(by[-1,:,:,1]),cmap='gray')\n",
    "                            ax2.set_title(\"Ground Truth\")\n",
    "                            f.subplots_adjust(hspace=5.0)\n",
    "                            plt.show()\n",
    "                                    \n",
    "                        i+=trunc_prop\n",
    "                        ct+=trunc_prop\n",
    "                        \n",
    "                    print(\"Validation Subject \" + str(subj_val) + \" Dice Similarity Coeff = \" + str(np.mean(DSC_val_vec)) + \" +- \" + str(np.std(DSC_val_vec)))\n",
    "                    print(' ')\n",
    "                    \n",
    "\n",
    "print(\"We out here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test session\n",
    "\n",
    "ct = 0\n",
    "with tf.Session() as sess:\n",
    "    #Test session\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #sess.run(init)\n",
    "    #Option to restore from model checkpoint to resume training\n",
    "    #saver.restore(sess, '/models/model_17055_Original')\n",
    "\n",
    "    # Import variables from trained U-Net\n",
    "    # transfer_saver.restore(sess, (path_to_model + '.data-00000-of-00001'))\n",
    "    #transfer_saver.restore(sess, (path_to_model))\n",
    "\n",
    "    #Initialize the rest of the variables\n",
    "    #sess.run(init_new_vars)\n",
    "    \n",
    "    saver.restore(sess, ('/models2/model_23094_' + plane_view + \"_CLSTM\"))\n",
    "    DSC_test_vec_total=[];\n",
    "    for subj_test in range(1,1+num_subj_test):\n",
    "        DSC_test_vec=[];\n",
    "        print(\"Test Subject \" + str(subj_test))\n",
    "\n",
    "        # Get stack of inputs -- Returns 4d tensor\n",
    "        images=get_pics((imdpath_test  + str(subj_test) + '/Imd/'))\n",
    "        images=images-np.mean(images)\n",
    "        # Get stack of outputs -- Returns 4d tensor\n",
    "        grounds=get_pics((pxdpath_test  + str(subj_test) + '/Pxd/'))\n",
    "\n",
    "        images=fix_dims(images)\n",
    "        grounds=fix_dims(grounds)\n",
    "\n",
    "        bxx=np.empty((images.shape[0],images.shape[1],images.shape[2],1)) # Intialize np matrix to hold all images\n",
    "        byy=np.empty((grounds.shape[0],grounds.shape[1],grounds.shape[2],num_classes)) # Intialize np matrix to hold all images\n",
    "\n",
    "        for j in range(images.shape[0]): # One-hot \n",
    "            byy[j,:,:,:] = get_one_hot(grounds[j,:,:,0], num_classes)\n",
    "            bxx[j,:,:,:] = images[j,:,:,:]\n",
    "\n",
    "        # Initialize cell and hidden for this subject\n",
    "        current_cell=[]; current_hidden=[];\n",
    "        for kk in range(2):\n",
    "            current_cell.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "            current_hidden.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "\n",
    "        i=0\n",
    "        # Because we are using a static_rnn, iterate through the subject [trunc_prop] slices at a time\n",
    "        while i+trunc_prop<=images.shape[0]:\n",
    "            bx=np.empty((trunc_prop, bxx.shape[1], bxx.shape[2], input_depth))\n",
    "            by=np.empty((trunc_prop, bxx.shape[1], bxx.shape[2], num_classes))\n",
    "\n",
    "            bx=bxx[i:i+trunc_prop,:,:,:] # Bx gets all the images in that batch\n",
    "            by=byy[i:i+trunc_prop,:,:,:]     \n",
    "            #by[0,:,:,:]=byy[i+trunc_prop-1,:,:,:] #By gets only last image\n",
    "\n",
    "            # loss, acc, summary, pred=sess.run([loss_op,accuracy,summ,prediction],feed_dict={X: bx, Y: by, cell_state[0]: current_cell[0], hidden_state[0]: current_hidden[0],cell_state[1]: current_cell[1], hidden_state[1]: current_hidden[1],cell_state[2]: current_cell[2], hidden_state[2]: current_hidden[2],cell_state[3]: current_cell[3], hidden_state[3]: current_hidden[3]})\n",
    "            DSC=sess.run(dice,feed_dict={X: bx, Y: by, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "            DSC_test_vec.append(DSC)\n",
    "            DSC_test_vec_total.append(DSC)\n",
    "\n",
    "            # After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "            current_cell, current_hidden =sess.run([cell_state, hidden_state],feed_dict={X: bx, Y: by, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "\n",
    "            # Unpack the state\n",
    "            # For kk in range(len(current_hidden)):\n",
    "            #    Current_cell[kk], current_hidden[kk] = current_total[kk]\n",
    "\n",
    "            if i==30:\n",
    "                #Verify data by displaying ground truth with original image that it is trying to predict\n",
    "                f , (ax1, ax2) = plt.subplots(1,2,sharey=True, figsize=(6,2))\n",
    "                ax1.set_title(\"Slice\")\n",
    "                ax1.imshow(np.squeeze(bx[-1,:,:,0]),cmap='gray')\n",
    "                ax2.imshow(np.squeeze(by[-1,:,:,1]),cmap='gray')\n",
    "                ax2.set_title(\"Ground Truth\")\n",
    "                f.subplots_adjust(hspace=5.0)\n",
    "                plt.show()\n",
    "\n",
    "            i+=trunc_prop\n",
    "            ct+=trunc_prop\n",
    "\n",
    "        print(\"Test Subject \" + str(subj_test) + \" Dice Similarity Coeff = \" + str(np.mean(DSC_test_vec)) + \" +- \" + str(np.std(DSC_test_vec)))\n",
    "        print(' ')\n",
    "        \n",
    "print(\"Test Statistics: Dice Similarity Coeff = \" + str(np.mean(DSC_test_vec_total)) + \" +- \" + str(np.std(DSC_test_vec_total)))\n",
    "               \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_function(images,trunc_prop):\n",
    "    if images.shape[0]%trunc_prop!=0:\n",
    "        while images.shape[0]%trunc_prop!=0:\n",
    "            temp=np.empty((images.shape[0]+1,images.shape[1],images.shape[2],1))\n",
    "            temp[:images.shape[0],:,:,:]=images\n",
    "            temp[-1,:,:,:]=images[-1,:,:,:] # Pad the last image\n",
    "            images=temp\n",
    "            \n",
    "    return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference session\n",
    "ct = 0\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #sess.run(init)\n",
    "    #Option to restore from model checkpoint to resume training\n",
    "    #saver.restore(sess, '/models/model_17055_Original')\n",
    "\n",
    "    # Import variables from trained U-Net\n",
    "    # transfer_saver.restore(sess, (path_to_model + '.data-00000-of-00001'))\n",
    "    #transfer_saver.restore(sess, (path_to_model))\n",
    "\n",
    "    #Initialize the rest of the variables\n",
    "    #sess.run(init_new_vars)\n",
    "    saver.restore(sess, ('/models2/model_23094_' + plane_view + \"_CLSTM\"))\n",
    "    \n",
    "    pathout='/output/Inference/'\n",
    "    if not (os.path.isdir(pathout)):   \n",
    "        os.mkdir(pathout)\n",
    "    \n",
    "    #saver.restore(sess, '/models/model_17055_Original')\n",
    "    DSC_test_total=[];\n",
    "    for subj_test in range(1,1+num_subj_test):\n",
    "        #Set up output path\n",
    "        \n",
    "        pathout='/output/Inference/' + str(subj_test) + '/'\n",
    "        if not (os.path.isdir(pathout)):\n",
    "            os.mkdir(pathout)   \n",
    "        pathout='/output/Inference/' + str(subj_test) + '/'  + plane_view + '/'\n",
    "        if not (os.path.isdir(pathout)):\n",
    "            os.mkdir(pathout)\n",
    "        \n",
    "        pathout='/output/Inference/' + str(subj_test) + '/' + plane_view + '/Inf/'\n",
    "        if not (os.path.isdir(pathout)):\n",
    "            os.mkdir(pathout)\n",
    "        \n",
    "        print(\"Test Subject \" + str(subj_test))\n",
    "        print(pathout)\n",
    "\n",
    "        # Get stack of inputs -- Returns 4d tensor\n",
    "        images=get_pics((imdpath_test  + str(subj_test) + '/Imd/'))\n",
    "        original_dims=images.shape\n",
    "        images=images-np.mean(images)\n",
    "        images=fix_dims(images)\n",
    "        images=padding_function(images, trunc_prop) # Function to pad sequence\n",
    "        bxx=np.empty((images.shape[0],images.shape[1],images.shape[2],1)) # Intialize np matrix to hold all images\n",
    "        for j in range(images.shape[0]): # One-hot \n",
    "            bxx[j,:,:,:] = images[j,:,:,:]\n",
    "\n",
    "        # Initialize cell and hidden for this subject\n",
    "        current_cell=[]; current_hidden=[];\n",
    "        for kk in range(2):\n",
    "            current_cell.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "            current_hidden.append(np.zeros((1, bxx.shape[1], bxx.shape[2], 64),dtype=np.float32))\n",
    "\n",
    "        i=0\n",
    "        # Because we are using a static_rnn, iterate through the subject [trunc_prop] slices at a time\n",
    "        while i+trunc_prop<=images.shape[0]:\n",
    "            bx=np.empty((trunc_prop, bxx.shape[1], bxx.shape[2], input_depth))\n",
    "            bx=bxx[i:i+trunc_prop,:,:,:] # Bx gets all the images in that batch  \n",
    "\n",
    "            probability_map=sess.run(prediction,feed_dict={X: bx, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "            if i==0:\n",
    "                print(probability_map.shape)\n",
    "            \n",
    "            # After iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "            current_cell, current_hidden =sess.run([cell_state, hidden_state],feed_dict={X: bx, cell_state_in[0]: current_cell[0], hidden_state_in[0]: current_hidden[0], cell_state_in[1]: current_cell[1], hidden_state_in[1]: current_hidden[1]})\n",
    "\n",
    "            # Export images\n",
    "            for kk in range(trunc_prop):\n",
    "                if i+kk<original_dims[0]: # Make sure you don't export the sequence padding\n",
    "                    fileID=str(i+kk)\n",
    "                    IDlength=6\n",
    "                    while len(fileID)<IDlength:\n",
    "                        fileID='0'+fileID\n",
    "                    if i==0:\n",
    "                        print((pathout + fileID + '.png'))\n",
    "\n",
    "                    imageio.imwrite(pathout + fileID + \".png\",np.squeeze(probability_map[kk,:original_dims[1],:original_dims[2],1]))\n",
    "\n",
    "            \n",
    "            \n",
    "            if i==30:\n",
    "                #Verify data by displaying ground truth with original image that it is trying to predict\n",
    "                f , (ax1, ax2) = plt.subplots(1,2,sharey=True, figsize=(6,2))\n",
    "                ax1.set_title(\"Slice\")\n",
    "                ax1.imshow(np.squeeze(bx[-1,:,:,0]),cmap='gray')\n",
    "                ax2.imshow(np.squeeze(bx[-1,:,:,0]),cmap='gray')\n",
    "                ax2.set_title(\"Ground Truth\")\n",
    "                f.subplots_adjust(hspace=5.0)\n",
    "                plt.show()\n",
    "\n",
    "            i+=trunc_prop\n",
    "            ct+=trunc_prop\n",
    "\n",
    "\n",
    "print(\"We out here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
