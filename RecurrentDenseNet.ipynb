{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "#Basically a densenet but the last fully connected layer is recurrent\n",
    "#Huang G, Liu Z, Weinberger KQ, van der Maaten L. Densely connected convolutional networks. ...\n",
    "#InProceedings of the IEEE conference on computer vision and pattern recognition 2017 Jul 1 (Vol. 1, No. 2, p. 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_files(num_files):\n",
    "    x = ([[i] for i in range(num_files)])\n",
    "    shuflist=random.sample(x,len(x))\n",
    "    list_files=[]\n",
    "\n",
    "    s=''\n",
    "    for i in range(num_files):\n",
    "        ID=str(shuflist[i][0])\n",
    "        while len(ID)<5:\n",
    "            ID='0'+ID\n",
    "        list_files.append(ID)\n",
    "        \n",
    "        \n",
    "    return list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list(path_ground):\n",
    "    s=''\n",
    "    classtrue=[]\n",
    "    \n",
    "    f = open(path_ground, 'r')\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if row[0]=='0':\n",
    "            sublist=(1,0)\n",
    "        else:\n",
    "            sublist=(0,1)\n",
    "    \n",
    "        classtrue.append(sublist)\n",
    "    f.close()\n",
    "    \n",
    "    by=np.empty((len(classtrue),num_classes))\n",
    "    for i in range(len(classtrue)):\n",
    "        by[i,:]=classtrue[i]\n",
    "\n",
    "    return by\n",
    "    \n",
    "def return_images(path,picsize,inputdepth):\n",
    "    inputdepth=7\n",
    "    numfiles=int(len(glob.glob(path+'*.png'))/7)\n",
    "    \n",
    "    images=np.empty((numfiles,picsize,picsize,1))\n",
    "    for i in range(numfiles):\n",
    "        ID=str(i)\n",
    "        while len(ID)<5:\n",
    "            ID='0'+ID\n",
    "        images[i,:,:,0]=imageio.imread((path + ID + 'D.png')) #Import slice\n",
    "        \n",
    "    return images\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_translate(input_block,y_dir,x_dir):\n",
    "    imsize=input_block.shape\n",
    "    temp=np.empty((imsize[0],imsize[1],imsize[2]))\n",
    "    y_abs=np.absolute(y_dir)\n",
    "    x_abs=np.absolute(x_dir)\n",
    "    \n",
    "    #Vertical translation\n",
    "    if y_dir != 0: \n",
    "        height_pad=np.zeros((y_abs,imsize[1],imsize[2]))\n",
    "        if y_dir>0: #Shift up --> attach zeros to bottom\n",
    "            temp=np.concatenate((input_block[y_abs:,:,:],height_pad),axis=0)\n",
    "        else: #Shift down --> attach zeros to top\n",
    "            temp=np.concatenate((height_pad,input_block[:(-1*y_abs),:,:]),axis=0)\n",
    "    else: \n",
    "        temp=input_block\n",
    "        \n",
    "    #Horizontal translation\n",
    "    if x_dir!=0:\n",
    "        width_pad=np.zeros((imsize[0],x_abs,imsize[2]))\n",
    "        if x_dir>0:\n",
    "            temp2=np.concatenate((width_pad,temp[:,:(-1*x_abs),:]),axis=1)\n",
    "        else: \n",
    "            temp2=np.concatenate((temp[:,x_abs:,:],width_pad),axis=1)\n",
    "    else:\n",
    "        temp2=temp\n",
    "        \n",
    "    return temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of files in training set and also median frequency class weights for cross entropy loss\n",
    "def get_num_files(path_ground):  \n",
    "    s=''\n",
    "    classtrue=[]\n",
    "    f = open(path_ground, 'r')\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if row[0]=='0':\n",
    "            sublist=(1,0)\n",
    "        else:\n",
    "            sublist=(0,1)\n",
    "    \n",
    "        classtrue.append(sublist)\n",
    "    f.close()\n",
    "    ground_vec=classtrue\n",
    "\n",
    "    return len(ground_vec), ground_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer wrappers\n",
    "def conv_layer(inputs, channels_in, channels_out,is_training,pad_val='SAME',stvs=0.01,filter_size=1,strides=1,scopename=\"conv\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        s=''; weightname=(scopename,'_weights'); biasname=(scopename,'_bias')\n",
    "        \n",
    "        w=tf.Variable(tf.random_normal([filter_size, filter_size, channels_in, channels_out],stddev=stvs),name=s.join(weightname))\n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, w)\n",
    "        b=tf.Variable(tf.random_normal([channels_out],stddev=stvs),name=s.join(biasname))\n",
    "        tf.summary.histogram((\"Weight\" + scopename),w)\n",
    "        tf.summary.histogram((\"Bias\" + scopename),b)\n",
    "        \n",
    "        x = tf.nn.conv2d(inputs, w, strides=[1, strides, strides, 1], padding=pad_val)\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        #x=batch_norm_wrapper(x, is_training, decay = 0.99)\n",
    "        #return tf.nn.relu(x)\n",
    "        return x\n",
    "        \n",
    "def BNR(inputs,is_training,scopename=\"BNR\"):\n",
    "    # Batch norm + ReLu\n",
    "    with tf.name_scope(scopename):\n",
    "        x=tf.contrib.layers.layer_norm(inputs)\n",
    "        return tf.nn.relu(x)\n",
    "    \n",
    "def shortcut_function(inputs,channels_in,num_filter_out,stvs=0.01,strides=1,scopename=\"shortcut\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        s=''; weightname=(scopename,'_weights')\n",
    "        filter_size=1\n",
    "        w=tf.Variable(tf.random_normal([filter_size, filter_size, channels_in, num_filter_out],stddev=stvs),name=s.join(weightname))\n",
    "       \n",
    "        shortcut = tf.nn.conv2d(inputs, w, strides=[1, strides, strides, 1], padding='VALID')\n",
    "        \n",
    "        return shortcut\n",
    "    \n",
    "def maxpool2d(x, k=2, stride=2,scopename=\"pool\"):\n",
    "    with tf.name_scope(scopename):\n",
    "        # MaxPool2D wrapper\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, stride, stride, 1],padding='VALID')\n",
    "\n",
    "def Denseblock(inputs,num_dense_layers,k,channels_current, is_training,scopename='Denseblock'):\n",
    "    \n",
    "    with tf.name_scope(scopename):\n",
    "        #Initialize shortcut list\n",
    "        shortcut=list()\n",
    "        shortcut.append(inputs)\n",
    "    \n",
    "        #Create first dense layer\n",
    "        x = Denselayer(inputs,channels_current,k, is_training,scopename=scopename)\n",
    "        shortcut.append(x); channels_current+=k #Iterate number of current channels\n",
    "    \n",
    "        for i in range(1,num_dense_layers):\n",
    "            x=tf.concat(shortcut,3)\n",
    "            x = Denselayer(x,channels_current,k, is_training,scopename=scopename)\n",
    "            shortcut.append(x); channels_current+=k\n",
    "    \n",
    "        out=tf.concat(shortcut,3)\n",
    "        \n",
    "        return out, channels_current       \n",
    "    \n",
    "def Denselayer(inputs,channels_current,k, is_training,scopename='Denselayer'):\n",
    "    \n",
    "    with tf.name_scope(scopename):\n",
    "        x=BNR(inputs,is_training,scopename=scopename)\n",
    "        x=conv_layer(x,channels_current,4*k, is_training,filter_size=1,scopename=scopename)\n",
    "    \n",
    "        x=BNR(x,is_training,scopename=scopename)\n",
    "        x=conv_layer(x,4*k,k, is_training,filter_size=3,scopename=scopename)\n",
    "    \n",
    "        return x        \n",
    "    \n",
    "def Transitionlayer(inputs, theta, channels_current, is_training,scopename='Tranny'):\n",
    "    \n",
    "    with tf.name_scope(scopename):\n",
    "     \n",
    "        # Conv\n",
    "        x=conv_layer(inputs,channels_current,int(channels_current*theta), is_training,filter_size=1,scopename=scopename)\n",
    "        channels_current=channels_current*theta\n",
    "    \n",
    "        # Pooling\n",
    "        avg_pool=tf.nn.pool(x, [2,2], \"AVG\", \"SAME\",strides=[2,2])\n",
    "    \n",
    "        return avg_pool, int(channels_current)\n",
    "    \n",
    "    \n",
    "# Batch normalization wrapper to distinguish between training and testing\n",
    "# REF: https://r2rt.com/implementing-batch-normalization-in-tensorflow.html\n",
    "def batch_norm_wrapper(inputs, is_training, decay = 0.99):\n",
    "    \n",
    "    epsilon = 1e-3\n",
    "    scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]))\n",
    "    beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]))\n",
    "    #pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-3], inputs.get_shape()[-2] ,inputs.get_shape()[-1]]), trainable=False)\n",
    "    #pop_var = tf.Variable(tf.ones([inputs.get_shape()[-3], inputs.get_shape()[-2] ,inputs.get_shape()[-1]]), trainable=False)\n",
    "    \n",
    "    pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable=False)\n",
    "    pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable=False)\n",
    "  \n",
    "    if is_training:\n",
    "        batch_mean, batch_var = tf.nn.moments(inputs,[0,1,2])\n",
    "        train_mean = tf.assign(pop_mean,\n",
    "                               pop_mean * decay + batch_mean * (1 - decay))\n",
    "        train_var = tf.assign(pop_var,\n",
    "                              pop_var * decay + batch_var * (1 - decay))\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs,\n",
    "                batch_mean, batch_var, beta, scale, epsilon)\n",
    "    else:\n",
    "        return tf.nn.batch_normalization(inputs,\n",
    "            pop_mean, pop_var, beta, scale, epsilon)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet(x, inputdepth, picsize, is_training, densenodes, trunc_prop):\n",
    "    depth_start=64\n",
    "    num_classes=2\n",
    "    inputdepth=1\n",
    "    stvs=0.01\n",
    "    k=12\n",
    "    theta=0.5\n",
    "    BS=1\n",
    "    trunc_prop=10\n",
    "    \n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, picsize, picsize, inputdepth]) \n",
    "    \n",
    "    # Initial conv_block\n",
    "    with tf.name_scope(\"Initial_Conv\"):\n",
    "        conv_initial = conv_layer(x, inputdepth, 2*k, is_training, filter_size=7, scopename=\"conv_initial\")\n",
    "        channels_current=2*k\n",
    "    \n",
    "    # Initial max pooling\n",
    "    with tf.name_scope(\"Max_Pool1\"):\n",
    "        # From 256 down to 128\n",
    "        pool_initial = maxpool2d(conv_initial,scopename=\"pool_initial\")\n",
    "          \n",
    "    # Dense block 1\n",
    "    scope_in=\"Denseblock1\"\n",
    "    with tf.name_scope(scope_in):\n",
    "        print(scope_in)\n",
    "        num_dense_layers=6\n",
    "        x, channels_current=Denseblock(pool_initial,num_dense_layers,k,channels_current, is_training,scopename=scope_in)\n",
    "        print(channels_current)\n",
    "        \n",
    "    # Transition 1\n",
    "    scope_in=\"Tranny1\"\n",
    "    with tf.name_scope(scope_in):\n",
    "        # From 128 to 64\n",
    "        print(scope_in)\n",
    "        x, channels_current=Transitionlayer(x, theta, channels_current, is_training,scopename=scope_in)\n",
    "        print(channels_current)\n",
    "        \n",
    "    # Dense block 2\n",
    "    scope_in=\"Denseblock2\"\n",
    "    with tf.name_scope(scope_in):\n",
    "        scope_in=scope_in\n",
    "        print(scope_in)\n",
    "        num_dense_layers=12\n",
    "        x, channels_current=Denseblock(x,num_dense_layers,k,channels_current, is_training,scopename=scope_in)\n",
    "        print(channels_current)\n",
    "        \n",
    "    # Transition 2\n",
    "    scope_in=\"Tranny2\"\n",
    "    with tf.name_scope(scope_in):\n",
    "        # From 64 to 32\n",
    "        print(scope_in)\n",
    "        x, channels_current=Transitionlayer(x, theta, channels_current, is_training,scopename=scope_in)\n",
    "        print(channels_current)\n",
    "        \n",
    "    # Dense block 3\n",
    "    with tf.name_scope(scope_in):\n",
    "        scope_in=\"Denseblock3\"\n",
    "        print(scope_in)\n",
    "        num_dense_layers=24\n",
    "        x, channels_current=Denseblock(x,num_dense_layers,k,channels_current, is_training,scopename=scope_in)\n",
    "        print(channels_current)\n",
    "        \n",
    "    # Transition 3\n",
    "    scope_in=\"Tranny3\"\n",
    "    with tf.name_scope(scope_in):\n",
    "        # From 32 to 16\n",
    "        print(scope_in)\n",
    "        x, channels_current=Transitionlayer(x, theta, channels_current, is_training,scopename=scope_in)\n",
    "        print(channels_current)\n",
    "        \n",
    "    # Dense block 4     \n",
    "    scope_in=\"Denseblock4\"\n",
    "    with tf.name_scope(scope_in):\n",
    "        print(scope_in)\n",
    "        num_dense_layers=16\n",
    "        x, channels_current=Denseblock(x,num_dense_layers,k,channels_current, is_training,scopename=scope_in)\n",
    "        print(channels_current)\n",
    "    \n",
    "    # Average pool\n",
    "    with tf.name_scope(\"Average_Pool_final\"):\n",
    "        # From 16 to 8\n",
    "        avg_pool=tf.nn.pool(x, [2,2], \"AVG\", \"SAME\",strides=[2,2])\n",
    "    \n",
    "  \n",
    "    # Fully connected\n",
    "    with tf.name_scope(\"Dense\"):\n",
    "        #Flatten for fully connected\n",
    "        #print(channels_current)\n",
    "        #print((picsize/(2**5)))\n",
    "        nodes_in=int(channels_current*(picsize/(2**5))*(picsize/(2**5)))\n",
    "        print(nodes_in)\n",
    "        flatten=tf.reshape(avg_pool,[-1,nodes_in])\n",
    "\n",
    "        # RNN time --> First we need to rearrange the data format into [BS,time_steps, vars]\n",
    "        # We want the timestep to become the batches and the batch size becomes 1.\n",
    "        flat_extend=tf.expand_dims(flatten,axis=0) #--> Now we are in [BS,timesteps,vars] format\n",
    "        \n",
    "        # Unpack the tensor to be a list of tensors at each time step\n",
    "        flat_unstack=tf.unstack(flat_extend,trunc_prop,axis=1) # Unpack axis 1\n",
    "        \n",
    "        cell_state = tf.placeholder(tf.float32, [BS, densenodes])\n",
    "        hidden_state = tf.placeholder(tf.float32, [BS, densenodes])\n",
    "        init_state = rnn.LSTMStateTuple(cell_state, hidden_state)\n",
    "        \n",
    "        lstm_cell = rnn.BasicLSTMCell(densenodes, state_is_tuple=True)\n",
    "        \n",
    "        outputs, states = rnn.static_rnn(lstm_cell, flat_unstack, init_state, dtype=tf.float32)\n",
    "        \n",
    "\n",
    "        \n",
    "    # Compress to num_classes for prediction\n",
    "    with tf.name_scope(\"Out_Layer\"):\n",
    "          \n",
    "        outvars={'weights':tf.Variable(tf.random_normal([densenodes, num_classes],stddev=stvs)), \n",
    "                'biases':tf.Variable(tf.random_normal([num_classes],stddev=stvs))}\n",
    "        \n",
    "        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, outvars['weights'])\n",
    "        \n",
    "        outlayer=[tf.matmul(output, outvars['weights']) + outvars['biases'] for output in outputs]\n",
    "        \n",
    "        #outlayer=tf.add(tf.matmul(dense,outvars['weights']),outvars['biases'])\n",
    "        \n",
    "    return tf.concat(outlayer,0) , states, cell_state, hidden_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(trainmode, inputdepth, num_classes, picsize, densenodes, trunc_prop):\n",
    "\n",
    "    #Define placeholders\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        X = tf.placeholder(tf.float32, [None, picsize, picsize, inputdepth])\n",
    "    with tf.name_scope(\"Ground_Truth\"):\n",
    "        Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "    \n",
    "    #Define flow graph\n",
    "    logits, states, cell_state, hidden_state = densenet(X, inputdepth, picsize, trainmode, densenodes, trunc_prop) ###<---IS TRAINING\n",
    "\n",
    "    #Prediction function for evaluating accuracy\n",
    "    with tf.name_scope(\"Softmax\"):\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    #Define Loss\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=0.0001)\n",
    "        reg_variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        reg_term = tf.contrib.layers.apply_regularization(regularizer, reg_variables)\n",
    "        loss_op += reg_term\n",
    "\n",
    "        tf.summary.scalar(\"Loss\",loss_op)\n",
    "\n",
    "    #Define optimizer\n",
    "    with tf.name_scope(\"Optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)   \n",
    "\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "        \n",
    "    # Evaluate model\n",
    "    with tf.name_scope(\"Accuracy\"):\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, axis=1), tf.argmax(Y, axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\",accuracy)\n",
    "\n",
    "    #Confusion matrix\n",
    "    with tf.name_scope(\"Confusion_Matrix\"):\n",
    "        batch_confusion = tf.confusion_matrix(tf.reshape(tf.argmax(Y,axis=1),[-1]),tf.reshape(tf.argmax(prediction,axis=1),[-1]),num_classes=num_classes,name='batch_confusion')\n",
    "        confusion_image = tf.reshape( tf.cast(batch_confusion, tf.float32),[1, num_classes, num_classes, 1])\n",
    "        tf.summary.image('confusion',confusion_image)\n",
    "\n",
    "    #Define writer for Tensorboard\n",
    "    writer=tf.summary.FileWriter(\"/output/12\")\n",
    "    writer_val=tf.summary.FileWriter(\"/output/4\")\n",
    "    summ=tf.summary.merge_all()\n",
    "\n",
    "    # Initialize the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    #Define saver for model saver\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    \n",
    "    return X, Y,  logits, states, cell_state, hidden_state, prediction, loss_op, train_op, accuracy, batch_confusion, confusion_image, writer, writer_val, summ, init, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.00001\n",
    "batch_size = 1\n",
    "display_step = batch_size*10\n",
    "hm_epochs=30\n",
    "BS=batch_size\n",
    "picsize=256\n",
    "inputdepth=1\n",
    "num_classes=2\n",
    "densenodes=1000\n",
    "trunc_prop=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denseblock1\n",
      "96\n",
      "Tranny1\n",
      "48\n",
      "Denseblock2\n",
      "192\n",
      "Tranny2\n",
      "96\n",
      "Denseblock3\n",
      "384\n",
      "Tranny3\n",
      "192\n",
      "Denseblock4\n",
      "384\n",
      "24576\n",
      "Graph built\n"
     ]
    }
   ],
   "source": [
    "train_mode=True\n",
    "tf.reset_default_graph()\n",
    "X, Y, logits, states, cell_state, hidden_state, prediction, loss_op, train_op, accuracy, batch_confusion, confusion_image, writer, writer_val, summ, init, saver = build_graph(train_mode, inputdepth, num_classes, picsize, densenodes, trunc_prop)\n",
    "\n",
    "print('Graph built')\n",
    "\n",
    "num_subj_train=17; num_subj_val=2; num_subj_test=2;\n",
    "\n",
    "mode=''\n",
    "if mode=='j':    \n",
    "    imdpath=\"/path/to/dir/Knee_MRI2/Femur/Train/ImdTrain/\"\n",
    "    pxdpath=\"/path/to/label/csv/Femur/Train/fem_mri_classlist_Train.csv\"\n",
    "\n",
    "    imdpath_val=\"/path/to/dir/Knee_MRI2/Femur/Val/ImdVal/\"\n",
    "    pxdpath_val=\"/path/to/label/csv/Femur/Val/fem_mri_classlist_Val.csv\"\n",
    "    \n",
    "    imdpath_test=\"/path/to/dir/Knee_MRI2/Femur/Test/ImdTest/\"\n",
    "    pxdpath_test=\"/path/to/label/csv/Femur/Test/fem_mri_classlist_Test.csv\"\n",
    "        \n",
    "    root = '/path/to/dir/Knee_MRI2/Femur/'\n",
    "    \n",
    "else:\n",
    "    imdpath=\"/mydata/Femur/Train/ImdTrain/\"\n",
    "    pxdpath=\"/mydata/Femur/Train/fem_mri_classlist_Train.csv\"\n",
    "\n",
    "    imdpath_val=\"/mydata/Femur/Val/ImdVal/\"\n",
    "    pxdpath_val=\"/mydata/Femur/Val/fem_mri_classlist_Val.csv\"\n",
    "    \n",
    "    imdpath_test=\"/mydata/Femur/Test/ImdTest/\"\n",
    "    pxdpath_test=\"/mydata/Femur/Test/fem_mri_classlist_Test.csv\"\n",
    "    \n",
    "    root = '/mydata/Femur/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Send it\n",
    "ct=0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer.add_graph(sess.graph)\n",
    "    #saver.restore(sess, '/models/model_30112') #Option to restore a model to resume training\n",
    "    \n",
    "    for epoch in range(hm_epochs):\n",
    "        print(\"EPOCH \" + \"{:d}\".format(epoch))\n",
    "        \n",
    "        for subj in range(num_subj_train):\n",
    "            prediction_vec=[]; logits_vec=[]; ground_vec=[];\n",
    "            print(\"Subject \" + str(subj))\n",
    "        \n",
    "            byy = return_list(root + 'Train/fem_mri_classlist_Train_subj' + str(subj) + '.csv')\n",
    "            images = return_images((imdpath+ str(subj) + '/'),picsize,inputdepth)\n",
    "            images=images-np.mean(images)\n",
    "            \n",
    "            x_stvs=15; y_stvs=15; \n",
    "            x_t=int(x_stvs*np.random.randn()); y_t=int(y_stvs*np.random.randn());\n",
    "            bxx=np.empty((images.shape[0],picsize,picsize,1))\n",
    "            \n",
    "            for j in range(images.shape[0]):\n",
    "                bxx[j,:,:,:]=random_translate(images[j,:,:,:],x_t,y_t)\n",
    "                \n",
    "            #Initialize cell and hidden for this subject\n",
    "            current_cell = np.zeros((BS, densenodes))\n",
    "            current_hidden = np.zeros((BS, densenodes))\n",
    "\n",
    "            i=0\n",
    "            # Because we are using a static_rnn, iterate through the subject \"trunc_prop\" slices at a time\n",
    "            while i+trunc_prop<=images.shape[0]:\n",
    "                \n",
    "                bx=np.empty((trunc_prop,picsize,picsize,inputdepth))\n",
    "                by=np.empty((trunc_prop,num_classes))\n",
    "                \n",
    "                bx=bxx[i:i+trunc_prop,:,:,:]\n",
    "                by=byy[i:i+trunc_prop,:]\n",
    "                \n",
    "                sess.run(train_op,feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "                loss, acc, summary, pred=sess.run([loss_op,accuracy,summ,prediction],feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "                \n",
    "                for kk in range(pred.shape[0]):\n",
    "                    prediction_vec.append(np.argmax(pred[kk,:]))\n",
    "                    ground_vec.append(by[kk,1])\n",
    "                    logits_vec.append(pred[kk,1])\n",
    "                \n",
    "                #After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "                current_total=sess.run(states,{X: bx, Y: by, cell_state: current_cell , hidden_state: current_hidden})\n",
    "                \n",
    "                #Unpack the state\n",
    "                current_cell, current_hidden = current_total\n",
    "                \n",
    "                writer.add_summary(summary, ct)\n",
    "                \n",
    "                i+=trunc_prop\n",
    "                ct+=trunc_prop\n",
    "            \n",
    "            # For the remaining slices in the subject, we need it to have the same amount of slices as the other truncated sequence lengths\n",
    "            # Pad on the final slice until we reach the correct sequence length\n",
    "            if images.shape[0]%trunc_prop!=0:\n",
    "            \n",
    "                trunc_prop_temp=images.shape[0]-i\n",
    "\n",
    "                bx=np.empty((trunc_prop,picsize,picsize,inputdepth))\n",
    "                by=np.empty((trunc_prop,num_classes))\n",
    "\n",
    "                bx[:trunc_prop_temp,:,:,:]=bxx[i:i+trunc_prop_temp,:,:,:]\n",
    "                by[:trunc_prop_temp,:]=byy[i:i+trunc_prop_temp,:]\n",
    "                i+=trunc_prop_temp\n",
    "\n",
    "                temp_ct=0;\n",
    "                while trunc_prop_temp+temp_ct<trunc_prop:\n",
    "                    bx[trunc_prop_temp+temp_ct,:,:,:]=bx[trunc_prop_temp-1,:,:,:]\n",
    "                    by[trunc_prop_temp+temp_ct,:]=by[trunc_prop_temp-1,:]\n",
    "                    i+=1; temp_ct+=1\n",
    "\n",
    "\n",
    "                sess.run(train_op,feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "                loss, acc, summary, pred=sess.run([loss_op,accuracy,summ,prediction],feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "\n",
    "                for kk in range(pred.shape[0]):\n",
    "                    prediction_vec.append(np.argmax(pred[kk,:]))\n",
    "                    logits_vec.append(pred[kk,1])\n",
    "                    ground_vec.append(by[kk,1])\n",
    "                    \n",
    "                # After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "                current_total=sess.run(states,{X: bx, Y: by, cell_state: current_cell , hidden_state: current_hidden})\n",
    "\n",
    "                # Unpack the state\n",
    "                current_cell, current_hidden = current_total\n",
    "\n",
    "                writer.add_summary(summary, ct)\n",
    "\n",
    "                i+=trunc_prop_temp\n",
    "                ct+=trunc_prop_temp\n",
    "                \n",
    "            plt.plot(prediction_vec,'r',logits_vec,'g',ground_vec,'k--')\n",
    "            plt.ylabel('Subject Predictions')\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "            \n",
    "            if subj>0 and subj%10==0:# Save every 5 subjects\n",
    "                \n",
    "                s=''\n",
    "                checkpointnamelist=('./model_',str(ct))\n",
    "                checkpointname= s.join(checkpointnamelist)\n",
    "                save_path = saver.save(sess,checkpointname)\n",
    "                \n",
    "                #print(\"Model saved in file: %s\" % save_path)\n",
    "                #print(\" Step \" + str(i) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Training Accuracy = \" + \"{:.3f}\".format(acc)) \n",
    "                #print(sess.run(batch_confusion,feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden}))\n",
    "                \n",
    "                #Show example image from batch with ground truth\n",
    "                #temp=np.squeeze(bx[0,:,:,:])\n",
    "                #plt.imshow(temp,cmap='gray')\n",
    "                #plt.show()\n",
    "                #print(by[0,:])\n",
    "    \n",
    "            \n",
    "            #VALIDATION\n",
    "            if subj>0 and subj%10==0:    \n",
    "            \n",
    "                acc_vec_val=[]; ct_val=0;\n",
    "                seq_vec=[];\n",
    "                for j in range(num_subj_val): # Import data for that mini-batch\n",
    "                    print(\"Val Subject \" + str(j))\n",
    "                    prediction_vec=[]; logits_vec=[]; ground_vec=[];\n",
    "                    \n",
    "                    byy = return_list(root + 'Val/fem_mri_classlist_Val_subj' + str(j) + '.csv')\n",
    "                    images = return_images((imdpath_val+ str(j) + '/'),picsize,inputdepth)\n",
    "                    images=images-np.mean(images)\n",
    "                    bxx=images\n",
    "\n",
    "                    #Initialize cell and hidden for this subject\n",
    "                    current_cell = np.zeros((BS, densenodes))\n",
    "                    current_hidden = np.zeros((BS, densenodes))\n",
    "\n",
    "                    ii=0\n",
    "                    #Because we are using a static_rnn, iterate through the subject trunc_prop slices at a time\n",
    "                    while ii+trunc_prop<=images.shape[0]:\n",
    "                \n",
    "                        bx=np.empty((trunc_prop,picsize,picsize,inputdepth))\n",
    "                        by=np.empty((trunc_prop,num_classes))\n",
    "                \n",
    "                        bx=bxx[ii:ii+trunc_prop,:,:,:]\n",
    "                        by=byy[ii:ii+trunc_prop,:]\n",
    "                \n",
    "                        loss, acc, summary, pred=sess.run([loss_op,accuracy,summ, prediction],feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "                \n",
    "                        for kk in range(pred.shape[0]):\n",
    "                            prediction_vec.append(np.argmax(pred[kk,:]))\n",
    "                            logits_vec.append(pred[kk,1])\n",
    "                            ground_vec.append(by[kk,1])\n",
    "                \n",
    "                        #After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "                        current_total=sess.run(states,{X: bx, Y: by, cell_state: current_cell , hidden_state: current_hidden})\n",
    "                \n",
    "                        #Unpack the state\n",
    "                        current_cell, current_hidden = current_total\n",
    "                \n",
    "                        ii+=trunc_prop\n",
    "                        \n",
    "                        acc_vec_val.append(acc)\n",
    "                        seq_vec.append(trunc_prop)\n",
    "                    \n",
    "                    if images.shape[0]%trunc_prop!=0:\n",
    "                        #Run remaining slices through an iteration\n",
    "                        trunc_prop_temp=images.shape[0]-ii\n",
    "\n",
    "                        bx=np.empty((trunc_prop,picsize,picsize,inputdepth))\n",
    "                        by=np.empty((trunc_prop,num_classes))\n",
    "\n",
    "                        bx[:trunc_prop_temp,:,:,:]=bxx[ii:ii+trunc_prop_temp,:,:,:]\n",
    "                        by[:trunc_prop_temp,:]=byy[ii:ii+trunc_prop_temp,:]\n",
    "                        ii+=trunc_prop_temp\n",
    "\n",
    "                        temp_ct=0;\n",
    "                        while trunc_prop_temp+temp_ct<trunc_prop:\n",
    "                            bx[trunc_prop_temp+temp_ct,:,:,:]=bx[trunc_prop_temp-1,:,:,:]\n",
    "                            by[trunc_prop_temp+temp_ct,:]=by[trunc_prop_temp-1,:]\n",
    "                            ii+=1; temp_ct+=1\n",
    "\n",
    "                        loss, acc, summary, pred=sess.run([loss_op,accuracy,summ, prediction],feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "\n",
    "                        for kk in range(pred.shape[0]):\n",
    "                            prediction_vec.append(np.argmax(pred[kk,:]))\n",
    "                            logits_vec.append(pred[kk,1])\n",
    "                            ground_vec.append(by[kk,1])\n",
    "                        \n",
    "                        #After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "                        current_total=sess.run(states,{X: bx, Y: by, cell_state: current_cell , hidden_state: current_hidden})\n",
    "\n",
    "                        #Unpack the state\n",
    "                        current_cell, current_hidden = current_total\n",
    "\n",
    "                        acc_vec_val.append(acc)\n",
    "                        seq_vec.append(trunc_prop_temp)\n",
    "\n",
    "                        ii+=trunc_prop_temp\n",
    "                        \n",
    "                    plt.plot(prediction_vec,'r',logits_vec,'g',ground_vec,'k--')\n",
    "                    plt.ylabel('Subject Predictions')\n",
    "                    plt.show()\n",
    "                    \n",
    "                weighted_avg_vec=[];\n",
    "                for k in range(len(acc_vec_val)):\n",
    "                    weighted_avg_vec.append(acc_vec_val[k]*seq_vec[k]/sum(seq_vec))\n",
    "                    \n",
    "                print(\"Validation accuracy: \" + str(sum(weighted_avg_vec)))\n",
    "        \n",
    "    print(\"We out here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send it\n",
    "ct=0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer.add_graph(sess.graph)\n",
    "    saver.restore(sess, '/models/model_38292')\n",
    "    \n",
    "    for j in range(num_subj_test): # Import data for that mini-batch\n",
    "        acc_vec_val=[]; ct_val=0; seq_vec=[];\n",
    "        print(\"Test Subject \" + str(j))\n",
    "        prediction_vec=[]; logits_vec=[]; ground_vec=[];\n",
    "        \n",
    "        byy = return_list(root + 'Test/fem_mri_classlist_Test_subj' + str(j) + '.csv')\n",
    "        images = return_images((imdpath_val+ str(j) + '/'),picsize,inputdepth)\n",
    "        images=images-np.mean(images)\n",
    "        bxx=images\n",
    "\n",
    "        #Initialize cell and hidden for this subject\n",
    "        current_cell = np.zeros((BS, densenodes))\n",
    "        current_hidden = np.zeros((BS, densenodes))\n",
    "\n",
    "        ii=0\n",
    "        #Because we are using a static_rnn, iterate through the subject trunc_prop slices at a time\n",
    "        while ii+trunc_prop<=images.shape[0]:\n",
    "\n",
    "            bx=np.empty((trunc_prop,picsize,picsize,inputdepth))\n",
    "            by=np.empty((trunc_prop,num_classes))\n",
    "\n",
    "            bx=bxx[ii:ii+trunc_prop,:,:,:]\n",
    "            by=byy[ii:ii+trunc_prop,:]\n",
    "\n",
    "            loss, acc, summary, pred=sess.run([loss_op,accuracy,summ, prediction],feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "\n",
    "            for kk in range(pred.shape[0]):\n",
    "                prediction_vec.append(np.argmax(pred[kk,:]))\n",
    "                logits_vec.append(pred[kk,1])\n",
    "                ground_vec.append(by[kk,1])\n",
    "\n",
    "            #After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "            current_total=sess.run(states,{X: bx, Y: by, cell_state: current_cell , hidden_state: current_hidden})\n",
    "\n",
    "            #Unpack the state\n",
    "            current_cell, current_hidden = current_total\n",
    "\n",
    "            ii+=trunc_prop\n",
    "\n",
    "            acc_vec_val.append(acc)\n",
    "            seq_vec.append(trunc_prop)\n",
    "\n",
    "        if images.shape[0]%trunc_prop!=0:\n",
    "            #Run remaining slices through an iteration\n",
    "            trunc_prop_temp=images.shape[0]-ii\n",
    "\n",
    "            bx=np.empty((trunc_prop,picsize,picsize,inputdepth))\n",
    "            by=np.empty((trunc_prop,num_classes))\n",
    "\n",
    "            bx[:trunc_prop_temp,:,:,:]=bxx[ii:ii+trunc_prop_temp,:,:,:]\n",
    "            by[:trunc_prop_temp,:]=byy[ii:ii+trunc_prop_temp,:]\n",
    "            ii+=trunc_prop_temp\n",
    "\n",
    "            temp_ct=0;\n",
    "            while trunc_prop_temp+temp_ct<trunc_prop:\n",
    "                bx[trunc_prop_temp+temp_ct,:,:,:]=bx[trunc_prop_temp-1,:,:,:]\n",
    "                by[trunc_prop_temp+temp_ct,:]=by[trunc_prop_temp-1,:]\n",
    "                ii+=1; temp_ct+=1\n",
    "\n",
    "            loss, acc, summary, pred=sess.run([loss_op,accuracy,summ, prediction],feed_dict={X: bx, Y: by, cell_state: current_cell ,hidden_state: current_hidden})\n",
    "\n",
    "            for kk in range(pred.shape[0]):\n",
    "                prediction_vec.append(np.argmax(pred[kk,:]))\n",
    "                logits_vec.append(pred[kk,1])\n",
    "                ground_vec.append(by[kk,1])\n",
    "\n",
    "            #After training iteration, retrieve cell and hidden states for next iteration in current subject\n",
    "            current_total=sess.run(states,{X: bx, Y: by, cell_state: current_cell , hidden_state: current_hidden})\n",
    "\n",
    "            #Unpack the state\n",
    "            current_cell, current_hidden = current_total\n",
    "\n",
    "            acc_vec_val.append(acc)\n",
    "            seq_vec.append(trunc_prop_temp)\n",
    "\n",
    "            ii+=trunc_prop_temp\n",
    "\n",
    "        plt.plot(prediction_vec,'r',logits_vec,'g',ground_vec,'k--')\n",
    "        plt.ylabel('Subject Predictions')\n",
    "        plt.show()\n",
    "\n",
    "        weighted_avg_vec=[];\n",
    "        for k in range(len(acc_vec_val)):\n",
    "            weighted_avg_vec.append(acc_vec_val[k]*seq_vec[k]/sum(seq_vec))\n",
    "\n",
    "        print(\"Test accuracy: \" + str(sum(weighted_avg_vec)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
